[0:00:01 - 0:00:27]
皆さんこんばんは、松尾研究室の川崎と申します本日は、大規模言語モデル講座Day2ってことで、ライブで皆さんご参加いただいてありがとうございます。前回1450ぐらいだったのかな、に対して600名ぐらいですが、とも配もこの後参加していただくことを期待して講座を始めさせていただければと思います。

[0:00:27 - 0:00:58]
はい。本日ですねDay2になるDay2の講座になりますタイトルがPromptingとRAGで多分皆さんRAG周りかなり興味あるのかなと思っているのでぜひお楽しみにしていただければと思います講師はですね松尾研配属学生の原田さんと戸部去年ですねLLM講座受けられて、今内部の運営としても活躍いただいているベルトさんが編集BERTをあの後単語といただきますので、よろしくお願いします。

[0:00:59 - 0:02:40]
ちょっと最初開始に先立ちましてですねエポックの方から前回もコアの数ですけどもチャットボットの使い方改めて簡単にお伝えできればなというふうに思います。リンクがこちらになっていて、皆さんご自身のOmnicampusのアカウントでログインしていってこのリンク踏んでいただくと、この画面に出るのかなというふうに思ってます質疑応答はですね、前回帰漏らした方もいらっしゃるかと思うので改めて説明すると、この子のあの子講座においての質疑応答はチャットボット今回からどんどん導入してますのでここからご質問いただけるかなというふうに思ってます基本的に前去年開催したLM講座の情報っていうのをRAGで入れてるのとそこで回答できないものに関してはGPT-4oが裏側で動いて回答するような仕組みになっていますおそらくほぼほぼそちらで回答できるのかなと思っているんですが、一部ですね、あの、何か解決しなかったりとかマルチなんで何回かこうやってやるうちになんかおかしな会話になっていったりだったりとかそういうことが考えられますので、そこのちょっとご案内をさせていただければと思いますまずこの右左上のこの質問をするってボタン押していただいて、講義海峡Day2第2回なんでこのPromptingとRAGで内容に関して質問の範囲に関しては講義の範囲内の話なのか、簡易回なのかその他なのかっていうのを選んでいただいて、質問を打っていただく感じですね。

[0:02:40 - 0:03:47]
送信すると、返ってくるので、はい返ってきましたねこれに対してですね必ずというかねかなりかなりお願いとしてもし解決した場合、このGoodボタンを押してください。もし解決までこのあと解決しなかったら再度下の質問を繰り返していただくと思うんですけど最終的に回答しなかったら、このバットボタンを押してくださいバッチボタン押していただくと運営側に通知が行くので、ベストエフォートになりますが、講師もしくは運営の者が回答する感じになります回答が進みましたら皆さんの名メールアドレス宛に通知があの講師からの回答がありましたって通知が来るはずなので、そちらで最終的な回答っていうのをご覧いただけるかなというふうに思ってますので、ちょっとそちらご参照、あの、あのそのような仕組みになってるっていうのをご理解の上ですねGoodByeGoodBERTボタンを押していただければというふうに思います。

[0:03:47 - 0:04:20]
でですねなんでそういう性質があるので、基本的にはスレッド1質問であの回、お使いいただければと思いますなんであの回答元々の最初の質問に対して回回答した場合は、あの質問に対して解決した場合解決しなかった場合はいずれかのボタンを押して、セッションを終わらしていただくと新しく別に質問された場合、されたい場合はですね、右下こちらこちらから新しいセッション始められますってあるので、そこでサイト再度新しい質問を行った。

[0:04:20 - 0:04:36]
打っていただければというような形でお願いできればと思いますのでよろしくお願いいたします本日ですね講義の中で、質疑応答の時間の間お腹切り取りたいと思ってますので、はい、ぜひこちらご活用いただければというふうに思ってますので、よろしくお願いします。

[0:04:38 - 0:05:13]
はいそうだ本日からですね前回は座学でだけでしたけれども、本日から各回ごとに演習の時間というのを設けていきたいと思います二値講義時間2時間だと思うんですけども大体90分ぐらいが最初講義で残り30分が、演習の時間っていうような配分で、基本的にはこのような配分で進めていければというふうに思ってますのでどうぞよろしくお願いします練習環境に関してはですね、また後ほど説明させていただきたいというふうに思ってますのでそちらのご案内、お待ちください。

[0:05:14 - 0:05:40]
一応本日はGoogleコラボを使用する予定でございます。はい。という形で講義の方始めていた始めていければなというふうに思います。原田さん、ご準備いかがでしょうか？はい、少々お待ちください。見えてますかね。

[0:05:40 - 0:06:11]
はい、大丈夫ですよろしくお願いします。お願いします。はい、皆さんこんばんはそれでは本日の授業PromptingとRAGについて話をしたいと思います篠原だけをですよろしくお願いします。軽く自己紹介なんですけれども松尾岩澤研の博士課程の理念です去年この講座が立ち上がったときに講座の資料作成や最終課題のコンペを作成していたりしました。

[0:06:11 - 0:06:31]
またGENIACっていうプロジェクトでは皆さんから提出されたモデルの評価を担当していたりもしました。やってる研究としてはですね、大規模言語モデルの文脈活用能力についてであったりとか、教育応用教育場面における大規模言語モデルをよというところで発表もしたりしています。

[0:06:31 - 0:06:56]
今回の講義は今回本日のPromptingとRAG来週の円周部分PretrainingでGPT2を実装するというところを担当します。よろしくお願いします。さて全体像の確認なんですが、本日はPromptingとRAGというところで、学習完了後の大規模言語モデルを活用する技術についてお話します。

[0:06:57 - 0:07:35]
他の講義との関係性でいうと、今回は学習なしでどうやって性能を上げるかという話なんですが、学習によって性能を向上させるテクニックっていうのは、第5回第7回第11回などで扱えます。そして今回言語言語モデル言語ドメインで言語だけでPromptingしたり言語情報だけで扱うんですが、音声や画像が与えられるようなマルチモーダル設定であったりロボット犯したり行動選択にモデルを使うというところは第12回で扱えます。

[0:07:37 - 0:08:03]
そして本日お話する内容がなぜ、なぜうまくいくのかその大規模言語モデルの中でどのようなことが起きていて、だから成功失敗するのかという話は第10回見て詳しくお話します。なので本日はですね、うまくその学習完了後のモデルを、こうやったらうまくいったというテクニック集を、いろんな論文からご紹介できればと思います。

[0:08:06 - 0:08:26]
本日の目的が追加学習せずに学習なしで活用する技術についてお話します。目標としてはPromptingと呼ばれる技術や文脈内学習という単語が何か説明できるようになる。そしてPromptingによって性能を改善する方法を自分自身で説明できるようになる。

[0:08:26 - 0:08:50]
そしてRAGを含む概念である下面とLanguageモデルの必要性と原理をご自身で説明できるようになるっていうのを目標にしています。演習では、実際にモデルをダウンロードして、今回学んだPromptingの技法を実装してもらうのと、RAGを実際に実装してもらうのが今回の本日の演習です。

[0:08:51 - 0:09:19]
それでは始めていきます。まず前回の復習で言語モデルとはなんぞやというところで、単語の系列文章の性生活確立をモデル化したものでした。特にこの文章というものを分解し、連鎖率で分解して、XはX次分Xは順々に繋げていって次モデル化したものは自己回帰言語モデルと呼ばれます。

[0:09:21 - 0:09:37]
このように条件つき確率がわかると生成Decodingすることもできるというところで、日本の人はその次に続く最もらしいもの、一番スコアが高いものを選ぶと、東京というような文章が出てくるという流れになります。

[0:09:40 - 0:09:59]
このようなモデルどのように学習しますかという話なんですが、ネクストtokenフリクションといって未来の位置一つ先のtoken単語を当てる学習をすることによって、言語モデルがうまく文章をモデル化する性能を高めていきます。

[0:09:59 - 0:10:25]
予測と正解の誤差を小さくするようにニューラルネットを学習していくというのが一連の流れです。そしてそのニューラルに何を使うかというところでTrasnformerというモデルが発表されておりまして、現在の主要なLLMは、大体がこのTrasnformerを使って、学習されてます大規模に学習されてますと。

[0:10:25 - 0:11:35]
実際にどのような処理が内部でなされるかというところは来週の講義で、理論面そして実装でも理解することを目指します。このようにTrasnformerで言語モデルをたくさん学習させると、様々な知識を持っていて、その知識を測るベンチマークでも高い性能が報告されていますと医学の知識もあるということが報告されてますとさらにさらにただその生の知識を評価するだけでなくてですね、普段の仕事、普段のタスクで、このLLMを使うことによって、何かリスク、効率化されたりする部分があるかというところも報告されていて、ビジネスコンサルタントさんがChatGPTを活用することによって、実務を模擬したタスクで質が向上していたり、またエンジニアの皆さん使ったことあるかもしれないんですが普段そのコードを書くというのもコードを生成するLLMを使うことによってアシストすることができて、エンジニアの生産性や満足度が向上しているというような事例も報告されています。

[0:11:37 - 0:12:13]
大規模言語モデルはですね大規模な学習データで大規模なモデルでたくさんの生産資源を使って学習させますとそうすることによって、たくさんの知識を持っていって、高性能なモデルがありますと。それがすごいコストをかけられて作られているものが、皆さんAPIを通じたりですとか実際にモデルを学習済みのモデルをダウンロードして簡単に利用することができますと、このモデルをどのようにうまく活用できるかその活用するための技術を学ぶのが本日になります。

[0:12:14 - 0:12:33]
モデルといってもいろいろありまして、大きく分けて三つあります。一つが非公開モデルというところで、論文としてはこういうモデル開発しましたよっていうところが公開されるんですが、それを使う術というのが、一部の研究機関であったり団体で限られている。

[0:12:33 - 0:13:05]
ていうモデルですと、有名なものとしてはGopherと呼ばれるものがあります。もう一つがAPIを通じてのみ利用できるというところで、モデルのニューラルネットの中の重みパラメーターは公開されてないんですけれども、そのAPIを通じて、プロンプト文を投げることでその分を投げて出力が得られるモデルが、APIのみでされるモデルですと、OpenAIが開始開発するGPTシリーズであったり、GoogleのGeminiシリーズAnthropicのClaudeシリーズがこちらに分類されるかなと思います。

[0:13:06 - 0:13:43]
最後に公開モデルというところで、モデルの重みのパラメータまで公開されていて誰でもダウンロードできるようになっておりますと、こちらのモデルのいいところとしましては、内部の処理を自分で可視化することもできるので、分析にも適していたり、あとそのモデルを使って、Fine-Tuningだったりすることができるので、カスタマイズ性が高いですとこれらのモデルとして有名なものとしてMeta社の開発するLlamaシリーズ今回の演習でも触るんですけどLlamaシリーズであったりミストラル、BloomFalconなどがあります。

[0:13:46 - 0:14:16]
これらモデル本当にいろいろ種類があるんですがどうやってモデルを、どのモデルを使うべきかと判断するときにも、これもまた軸がいろいろあるんですが、有名な視点で紹介しますとまずそのそれぞれが解きたいタスクというか、ものがあるとは思うんですがそれに近いデータで、そもそも学習されているかであったりとか、入力の文章どこまでの長さを受け付けるかというところがまず一つ注目するポイントかなと思います。

[0:14:16 - 0:14:33]
これらの点に関しては、モデルとともに公開されるテクニカルレポートというものがあるんですがそちらを参照することであったり、それがなかったとしてもそれのモデルを公開しているページがあるんですがそちらに記述されているところがあるのでそれを参照すると良いと思います。

[0:14:34 - 0:14:53]
なので僕自身見る視点としては、よく海外の有名な会社がモデル学習して公開したってなったらHuggingFaceのページを見て、Japaneseみたいな単語でとかJAとかJPとか、検索してどれぐらいのtoken数で学習してるかなみたいなところを見たりします。

[0:14:56 - 0:15:13]
次に既存の既にアカデミアでよく使うられるようなベンチマークで性能がどれほど出てるかというところも確認します。有名なものとしては、オープンLLMリーダーボードやチャットボットアリーナなどがあります。日本ではねずみリーダーボードというのも一つ有名かなと思います。

[0:15:15 - 0:15:40]
自分が解きたいタスクに近いベンチマークについてはある程度把握しておいて、それらのタスクでどれぐらい性能が出てくる出ているのかなというところ確認することがあります。そしてあとは推論モデルがでかすぎると、コストパフォーマンス合わないというところもあるかと思うのでそちらの話であったりとか、ライセンス利用規約などが、モデルを選ぶときのポイントかなと思います。

[0:15:43 - 0:16:20]
ベンチマークの一つちょっと紹介するんですがね地味リーダーボードというものが日本ではよく見られるかなと思います。このリーダーボードaWebandbyAshes者が開発してる日本の支社が開発してるものなんですけど日本のベンチマークいろいろ集めて、それらを評価した結果というのを総合したスコアなどを載せていますとそこを見ると、日本語で自分が解きたいタスクどれだろうというところも、ファクタすけのスコアとかも出てるので参照することができると思います。

[0:16:20 - 0:16:42]
そしてモデルごとの順位も総合スコアで、これは相当されてるんですけどどのモデルが良さそうかというところも見ることができます。大体がそのAPIで提供されてるモデルがあるかなと。日本で開発したモデルサイバーエージェントさんが開発したモデルはこれぐらいのスコア出るんだなというところがわかると思います。

[0:16:45 - 0:17:07]
他社が評価してるスコアを既存のベンチマークで評価され、評価してみるっていうのもいいんですが、やはり自分でも評価自分で作ったタスクで評価したいというところがあるかと思います。それらをサポートするツールもありますので単語というかそれだけの紹介をさせていただきます。

[0:17:07 - 0:18:18]
ただ、注意してほしいことは今回そのPromptingについて学ぶとわかると思うんですが、細かい違いによって同じモデルでも大きく異なるスコアが出るっていうのが、気をつけるポイントです。さてモデルを選びましたと、APIによって使うっていうのをどう使うか、そのイメージ簡単なイメージなんですが、こちらはOpenAI社が出してるモデルを使うときには、まずはAPIKeyというものを取得して、OpenAIが作ってるライブラリ専用のライブラリを使って、授業垂らすで何かタスクをお願いすると返してくれるということで、簡単に使えますと各社いろいろライブラーり出してるんですがそれら使い方を把握するのも大変かと思うのでちょっと僕がそれらをまとめたツールを使って作ってみたので、もし興味ある人が見てみてくださいそして、今回の演習でも今後の演習でもそして最終課題のコンペでもずっと使うことになるTrasnformer図と呼ばれるライブラリが公開モデルを使うための便利ライブラーのデファクトとして、あります。

[0:18:18 - 0:18:47]
こちら今回のこの講義としてずっと使うライブラリになりますので、ドキュメントやチュートリアルの一読をおすすめします。細かいことが気になる方は講座も公開されているのでそちらを見てください。さて前向きが前置きが長くなってしまったんですが、これから本題学習済みモデルを活用する技術についてお話します大きく分けて二つ話します。

[0:18:47 - 0:19:17]
一つがモデル一つだけを使って工夫するPrompting呼ばれる技術です。そもそもモデルでタスクを解くとはどういうことかと問い合わせと性能が引き出せるかなぜそのPromptingと呼ばれる技術が重要なのかについて前半をお話して、後半では、RAGが含まれる概念のものなんですけどメンテItLanguageModel、外部ツールや知識を利用する話についてお話します。

[0:19:20 - 0:19:47]
では前半話していきます。LLM皆さん触った事あるかと思うんですがこのように何か翻訳しお願いするだけで、英語を日本語に翻訳してくれたり、5歳児でもわかるように説明してというだけで、何かしら説明してくれたりと、指示に応じて同じモデルなんですけど指示に応じて返答が異なるという特徴があります。

[0:19:48 - 0:20:08]
モデルとお喋りしてるだけでも楽しいんですが、せっかくなので、この高性能なモデルを使ってどのように日々の生活に役立つであったりタスクを解くことができるか、言語モデルによってどのようにタスクを実行する、させることができるかという話が前半の話になります。

[0:20:11 - 0:21:14]
例えばQAを解かせたいとすると日本の人はどこかっていうところを機構とすると、東京と答えてほしいであったり、感情分析センチメント分析させようとして、このあのラーメン屋ラーメンはうまいという文章は、ポジティブかネガティブか、そういうことで企業のタスクセンチメント分析のタスクを解かせたいんですけれども言語モデル最もらしい文章の確立をモデル化してるわけなんですが、日本の人は、の後に必ず東京が続くとは限ら限りませんと日本の人はどこですかってあったり日本の人は京都ではないたり、平安時代の日本の人は平安京であったりと、今最もらしい文章というのはいくつか候補がありますとただ、狙っ狙いたい出力というか解かせたいタスクに応じて、より上手く入力とか条件を与えることで、そのタスクを解かせるための性能を高めることができないかというのが大きな問いです。

[0:21:16 - 0:21:37]
どのように指示出しをすると良いかというのがPromptingの技術になります。用語の確認なんですけどPromptingとはどういうものかといいますと、特定の機能の発生を促進これがプロンプトと呼ばれるんですが、促進するような言語モデルに入力するコンテキスト部になります。

[0:21:39 - 0:21:55]
センチうんて分析ぽじ値が判定をさせたいのであれば次の文章がポジティブかネガティブか分類してというように、その分類するような言語モデルが分離するような機能を発生を促進するような文章がプロンプトPromptingと呼びます。

[0:21:57 - 0:22:12]
Prompting様々なテクニックがあるんですが有名なものとしてFew-ShotPromptingと呼ばれるものがあります。このFew-ShotPromptingというものが何かといいますとまずこのタスクをし説明するタスク指示文佑です。

[0:22:12 - 0:22:30]
Descriptionというものがあります。こちらの例ですと、英語からフランス語に翻訳してくれというタスク指示文があります。それに追加して、実際にそれ、英語からフランス語に翻訳してるような例をデモンストレーション例を入れます。

[0:22:32 - 0:23:47]
これを英語翻訳するとこうなる英語矢印に、フランス語、英語矢印、フランス語となりますと、今回翻訳させたいものはチーズですと、チーズはどうなる。どうなりますか。というところで、デモンストレーション例も含めてどうなりますかと聞くのがFFew-ShotPromptingですと、このショットっていうのが例のデモンストレーションの数に対応していて、もう何も入れないものをZero-Shot1個だけ入れるものをワンショットで1個以上のものをFew-Shotと2個以上のものをFew-Shotとやりますとそれをの関係性、Few-Shotの数と性能の関係性を見てみますと、何も入れないZero-Shotだけですと、これ全部同じモデルを対象にしてるんですけど性能低いですと、これが0を入れる数が増えると良くなっていきますと、さらにこのデモンストレーション例を追加することで性能上がるあの幅っていうのが大大規模モデルが大きくなればなるほど、これが1.3Billon13億パラメータ130億パラメータ、1750億パラメーターのモデルの違いなんですが、その上がり幅っていうものも全然違いました。

[0:23:47 - 0:24:07]
モデルが大規模になればなるほど、このFew-Shotの性能が効きますとこのデモンストレーション例から、何かしらこのタスクの遂行をするということを学習するため特に分野区内学習院コンテキストLearningICLと略されることが多いんですが、そのような単語で呼ばれます。

[0:24:09 - 0:24:33]
従来のFine-Tuning重みパラメータを更新するFine-Tuningと何が違うかというところで、従来のFine-Tuningはパラメータ更新するので、性能が出やすかったり、そして毎回事例を入れなくていいのでその入力分が短くなるので、推論コストが低いというものがあるんですが、タスクごとに学習させないといけないというところで、学習コストがかかります。

[0:24:34 - 0:24:58]
それに対してFew-ShotPromptingのような文面文脈内学習では、パラメータ重みパラメータっていうのを更新せずに、1回作ったモデルを、どんなタスクでも使い回せますと映画史なので学習コストがかかりませんただFine-Tuningよりも性能が出にくいであったり、入力分が増えるので、水力コストが高くなるというところも言われています。

[0:25:00 - 0:25:15]
文脈内学習、このTrasnformerの内部でどのようなことが起きてるのか、分析してみると、技術的にFine-Tuningを実パラメータを更新するようなことと同じようなことが起きているんじゃないかと指摘する研究もあります。

[0:25:16 - 0:25:56]
そういうなんで、文脈内学習ができるのかという話その他諸々のなぜという部分は、第11回の講義でお話できればと思います。Promptingその指示出しを工夫することによって、質問ですと日本の人は何ですかと選択肢を与えて答えってところまで入れて、言語モデルに答えさせる、あるいは前提条件も足してあげることで、それに沿った答えを出させるというところで、プロンプトをうまく利用することによって、タスクも狙った。

[0:25:58 - 0:26:34]
振る舞いが制御できるかなと思います。プロンプトどんな文章でも同じように動作するかというとそういうわけでは全然なくてですね。プロンプトうまく書かないと、同じモデル同じタスクを解かせてるんですけど全然経精度が違いますというところも報告されていて、こちらはニュースのカテゴリー分類をさせるタスクなんですけど適当にそのタスクを表す文章というのをいろいろバリエーションを持たせて実験してみると、30ポイントぐらい性能が違う。

[0:26:34 - 0:27:03]
同じモデル名に違ってくるというところがありますのでプロンプトどういうブログと書くか、が重要ですというところがあります。本当に細かいところで違うというところで、こちらも紹介させていただくんですけど、質問との間に空白があるかどうかクエスチョンっていう文言があるか、タスクの説明をきちんとしてるかっていうところで、全然性能が違ってくるというところが報告されています。

[0:27:03 - 0:27:58]
なのでプロンプトきちんと設計しましょうというのが大事になります。だってFew-Shot入れれば入れるほど良くなるのかというところも気になるとは思うんですが最近の研究ですと、Few-Shotと呼ばれるのが5から10とかだったんですが、最近ROMコンテキストでいろいろ入力文が入るようになってひたすら入力部分に突っ込んでみたらどうなるかみたいなところが報告されているんですけど入力文にデモンストレーションで入れれば入れるほど良くなるっていうところが報告されていて、タスクによってはですね、その文脈内学習モデルの重みは更新してないんですけどその事例をうまく入れてあげるだけで、そのタスク特価で学習させたタスク特化のモデル構造であったりタスクとかのデータで学習させたモデルと匹敵するような性能も報告しています。

[0:28:03 - 0:28:23]
さてここまでがPromptingの有名なテクニックであるFew-ShotPromptingについてお話しました。次に、こっちこれもまた有名でどのモデルでも聞くということが報告されてるのがTuningSoftPrompting日本語だと思考の連鎖Promptingと呼ばれるものについてお話します。

[0:28:24 - 0:28:51]
こちらはそのFew-Shotの事例、そのデモンストレーションのときにその、なぜその答えに至るかの思考過程を得るこのJWebthoughtPrompting思考過程転移ofthoughtを入れると、新しい質問が与えられたとしても、その答えを出すための過程を出力しながら答えて、それがタスクの性能に繋がるということが報告されています。

[0:28:53 - 0:29:48]
日本語でちょっと例を示しますとこちらが今まで説明したワンショットFew-ShotPromptingですと質問が与えられて、答えがこうなります新たな質問が与えられてどうなるかっていうところで、出力だけさせると違うんですが、デモンストレーションのときにただ答えだけ入れるのではなくて、その途中の計算結果を入れたりしてその施工の手順を含めてPromptingしてあげると、実際に新しいタスクが来たときも同じような手順で途中経過を踏んで答えさせますと、なんでこっちはなんか暗算させてるイメージなんですけど、もちろん実際に出力しながら考えモデルの思考能力を促進させて、そのため性能が上がるというところが報告されたPromptingになります。

[0:29:50 - 0:30:19]
こちら様々な数学のデータセットで検証してみると、性能が大幅に上がるというところが報告されていて、こちらも特にモデルサイズが大きいときに性能の改善が大きいというところで、こちらのX軸がモデルサイズ、どれぐらいのパラメータ数のモデルか、縦軸がタスクの成功率なんですけれども、この一番右のところがすごい跳ね上がってるところが確認できるかなと思います。

[0:30:21 - 0:30:34]
なのでチェーンを想定がどれでも効くかっていうとそうでもなくて、皆さんが使おうとしてるモデルがどれぐらいのサイズだからうまくいくうまくいかないというところもあるかなと思うのでこちらの性質もちょっと覚えておいてください。

[0:30:37 - 0:31:24]
チーム総とPrompting思考の連鎖Promptingの派生としてZero-ShotChainofthoughtPromptingと呼ばれるものがありますと今までの例ですと、先ほど説明した通りに、その算数の数学の途中過程というのを事例に入れて答えさせるんですが、この事例なしで、ただレッツSyncステップバイステップという文言を入れるだけで、思考過程踏んでくれるエプロン出力になりますとそれで性能が上がりますと報告されたのがこのレッツスイングステップバイステップという文言で有名なZero-ShotCoTと呼ばれるものですこちらが松尾岩澤研のコジマが発表した論文になります。

[0:31:26 - 0:31:49]
これ使ってみると、多段階推論何回かそのステップを踏んで解かないといけないようなタスクにおいて、ステップバイステップと入れなかったZero-Shotと比べてZero-ShotCoTステップバイステップっていろいろと大幅に性能が向上してますと失敗する例としてはちょっと考えすぎて失敗する例が多いというところも報告されています。

[0:31:53 - 0:32:15]
こちらどういう文章を入れると、そういう思考の連鎖みたいなのが促進されるかというところでいろいろ調べてみましたと関係ない文章とかも入れてたりするんですが、ステップバイステップといえるのが、その小島さん人力探索で良さそうだというところが言われてました。

[0:32:16 - 0:32:45]
このプロンプトどれが効くかっていうのを探すのも大変なので、これを自動でプロンプト探索しましょうというところも言われてますとタスクの性能が上がった、下がったそのプロンプト分、どのプロンプト入れるべきかっていうところを探索して、その結果連続値6PEFTbyStepよりも、ネットワークthisOUTinStepbyStepDay2ABCIDRAMAlignDancerみたいな感じで入れると、探索結果これが良くなる。

[0:32:45 - 0:33:20]
ていうところも報告されています。ステップバイステップだけじゃなくて、どういうふうに解いてくれっとだけその思考をどういうふうに答えるべきかというところもプロンプトしてあげると、それに沿ってそのフレームワークがいいと性能が良くなるというところも言われていまして、検査計画を立ててから実行性をやったりとか必要な変数を保持せよみたいな感じでPromptingしてあげるとそういうふうに振舞って性能が上がるというところも報告されています。

[0:33:23 - 0:33:47]
ここまでがPrompting入力部にどのように条件づけしてあげることで、LLM大規模言語モデルの機能を促進させるかというところをお話しました。次にDecodingの工夫というところで、文章を工夫するんじゃなくて、モデルの推論時に工夫する手法を少しお話したいと思います。

[0:33:48 - 0:34:08]
一つがSelf-Consistencyと呼ばれるものですと、これが何をしてるかというと、今まではプロンプト与えて大規模言語モデルに1回出力させてましたと。それだけじゃなくて1回だけ出力させるんじゃなくて何個か後方出力させます。

[0:34:08 - 0:34:33]
言語モデル確率的にモデル化してるので最もらしい文章、最もらしいものがサンプリングによって出力できますと、その特性を生かしまして、何個か同じ問題に対して、同じモデルで何個か出力文をさせますとその上で、多数決で答えをどれだろうということを決定させるというのがSelf-Consistencyです。

[0:34:33 - 0:34:52]
マジョリティーボートとか言われてします。ええ。これが示唆するところっていうのが一番高い確率を出力すれば、答えになるんではなくて、分析に最もらしいものが正しい推論とは限らないことを示唆していることでもあります。

[0:34:54 - 0:35:42]
また似たような話として釣り用具装置というものがありますとこちらがどういうことをしてるか、このグラフで説明するんですが普通のインプットを与えて出力させるっていうものがふええ、ありましたチーム総と使うと、このアウトプットに至るまでの過程を出力させますそして、S、こういうことになるはずだとなりますSelf-Consistencyと呼ばれるものが、それを複数作ってあげて、多数決でこうなるはずだというのを決めますとトリオ部ソースっていうのは、それぞれのこの思考過程というものも分岐させてあげてどれが正しそうかというのを分岐させて分岐させてあげて、これが答えになるはずだと選ぶのが強く卒です。

[0:35:45 - 0:36:25]
こちら今までの手法同じモデルなんですけれども、何回も推論させることによって、生の加除向上させる手法になりますとそれらを使うと、これもいいことがあって、1回だけの推論だと、一番左下のスコアなんですけど、何かそのモデルを推論させるか、を増やせば増やすごとにこれは数学での性能なんですけれども上がっていくというところで、今あるモデルをうまく活用するという、技術としてのDecodingの工夫をしてあげることで大幅に性能を向上するということも報告されています。

[0:36:28 - 0:36:48]
はい。ここまでのまとめですと、まず言語モデルの入力プロンプトを工夫することで性能が改善します。コンテキストから学習モデルのパラメータというもの更新していなくて同じモデルを使ってるんですけどその入力文によって、学習しているように見えるため文脈内学習とも呼ばれます。

[0:36:49 - 0:37:05]
そしてプロンプトがあったりなかったりデモンストレーション例があったりなかったり、その細かい文言が違うことで性能が大きく変わることもあるので注意です。プロンプトテクニックとしては全部そうとであったりFew-ShotFショットPromptingなどがあります。

[0:37:06 - 0:37:19]
そしてさらにDecodingの工夫としてSelf-Consistencyやツリーオブソースというものがあります。特にチェーンソーとPromptingを使うと推論能力が大幅に向上しているというところが報告されています。

[0:37:21 - 0:37:54]
これらをいろいろまとめた論文であったり個別タスクをどうPromptingで解くかというところが知りたい方はぜひ文献を参照してください。ここまでの話のちょっとしたおまけなんですけれども、これらをゴリゴリ使うとどこまで上がるかっていうところで目処プロンプトと呼ばれる手法があって、Zero-Shotのときの性能が81.7点なんですけど、Few-Shot入れたりこのFew-Shotにどのような入れ例を入れるべきか、その近い例を持ってくる。

[0:37:54 - 0:38:15]
そのときに何かリトリーブしてくるみたいな感じなんですけど、入れてあげてさらに何個か、作ってあげてマジョリティーぼうとすると、10ポイントぐらい性能が変わってきますよっていうところも報告されています。今までの話を踏まえるとこの論文も読みこなせるかなと思うのでぜひ見てみてください。

[0:38:17 - 0:38:43]
さらにLLMでPromptingさせることでいろんな機能を促進できるんですがそれを使って、LLMに分を評価させたり何かしら評価させるっていうこともされてますと既存のベンチマークだと評価が難しいものもLLMを使うことによって人間の評価といって一致するようなものが作れるので、LLMに評価させましょうみたいな流れもあったりします。

[0:38:45 - 0:39:07]
さらにさらにモデルの振る舞いをちょっとPromptingによって攻撃してあげようというところで、攻撃する手法であったり、その爆弾の作り方みたいなこと、そういう危ないことを言わせないようにモデル訓練されてるんですが、こういう謎の文字列を出してあげることでペラペラと喋っちゃうみたいなことも言われています。

[0:39:07 - 0:39:38]
ところでPromptingPromptingにはいろんな機能があります。すごい不思議な部分も多いんですがそれもいろいろ研究されてますというのが、おまけ程度の紹介になります。もっといろんなユースケースでどうPromptingすべきかみたいなところは、アンドリー円先生という、ディープラーニング.AIという企業での人がいろいろ講座を開いてるんですがそちらへ松尾研岩澤県が中心となって翻訳した。

[0:39:39 - 0:39:56]
コースがあるので詳しく知りたい方はぜひ動画で知りたい方はぜひ見てみてください。はい。前半部分Prompting2については、一旦終了したのでここで質問の時間をとりたいと思いますが、川崎さんお願いしたんですか。

[0:39:57 - 0:40:12]
はい、ありがとうございます。まずですねなんか若干資料が違うというような指摘があったんですがこれって最新版になってますかね。最新版はまだアップロードしてないですちょっとそのときギリギリまでやってたのですいませんなるほど。

[0:40:12 - 0:40:25]
はいとのことなのですいません受講生の方ちょっと若干ページが合ってないと思いますが、ちょっと行ってこの講義終わってからですね、共有しますので、しばらくお待ちください。なんで講師のあの画像、あの画面を見ていただければと思います。

[0:40:25 - 0:41:09]
よろしくお願いします。はい。では質問いくつかいただいててるので、回答できればと思いちょっと僕の方で画面共有していいですか。はい。はい。はい。ちょっと先ほどご案内した通りですねこちらのチャットボットで木庭と解決しなかったというフラグを立てていただいた方の中からちょっと直接講義の中で関係ありそうなやつをピックアップして、ちょっと優先度づけをさせていただいてますなので時間って何分ぐらいあるんでしたっけ原さん、5分ぐらいあるかなこの質問ってことですか。

[0:41:09 - 0:41:40]
そうですねはい。全然Gopher大丈夫ですはい、いただいてるやつ回答できればと思いますちょっと下から古い順でしたから回答していいただければと思いますまずここですね連載してどんどん掛け算していくとそこはさ、小さくなりますよねっていう質問ですが、どうでしょうか？検査率で自己回帰玄知子回帰の話で掛け算したスコアスコアって呼んでるのが、文章の最もらしさっていう感じなんですか。

[0:41:40 - 0:42:02]
でも他の組み合わせと最もらしさと比べると、長さによって、その1分の生成確率みたいなのが短ければ短いほど高くもなってくるとは思うんですがそうですね掛け算をしていくので、スコアとしては小さくなるっていうのはその通りです。

[0:42:02 - 0:42:53]
はい。はい。ありがとうございます次です。はい。ここ半年で開発するPrompting賞について過剰箇条書きで答えたのうち各項目の概要を教えてくださいとありますこれ既に何かいくつか回答しているんですが、これだとまだないのかな何か補足等あれば、原さんよろしくお願いしますいろいろあるんですが、ジェネラルにっていうか当たり前にするのはFew-ShotPromptingと転移ofthoughtPromptingで他にいろいろ発生あるんですがそれはタスクごとにTuningしたPromptingかなと思いますなので、どんなタスクでもジェネラルに聞くっていうのはその二つでタスクごとにどういうふうに解いてであったりとかそういう工夫がされるのかなと思うので、タスクごとによってはいろんな進展はありますという回答にします。

[0:42:53 - 0:43:29]
はい、ありがとうございます。では、次ですねこちら、プロンプトで同じ文章入力しても回答異なるなぜですかという質問です。そうですねこれが言語モデルからどう出力を得てるかにもよるんですけどその言語モデル確立をモデル化してるというかその次の単語に続くスコアが野山というかその確率があってそこから最もらしいものを選ぶであったりそこからサンプリングして、それぞれの確率をもとに持ってくる。

[0:43:30 - 0:44:07]
こともあるんですが、設定によっては、毎回同じ回答にすることもできますGreedyDecodingと呼ばれてるものが、その次の単語に関して一番高いスコアをひたすら取っていくっていうのがグリーDecodingですとただそれだとその多様性がなくなったりもしますので、とかタスクによっては向かないタスク例えばなんでしょうクリエイティブなタスクだといろいろ候補があって欲しいとは思うんですけど、そうなるとサンプリングそのいろんな確率の山があるんですけど、そこからサンプリングして出すというところでNuclearすサンプリングであったりとか、そういうものでやったりしますと。

[0:44:07 - 0:44:37]
なので、Decodingのやり方によって同じことにもできますし、違うこともできます。という回答にさせていただきます。はい、ありがとうございます。言ったんは、一応かなまた増えてるか。ちょっとこっから上のやつをちょっとピックアップして回答してもらえますかね、ここの範囲でちょっと見づらいかなと拡大できない。

[0:44:42 - 0:45:58]
どれがいいかどれも面白いんですが、プロンプトやプロンプトの話でPromptingプロンプト自体をLM生成させるアプローチに興味がありっていうところで、はい。それは難しいというわけでもなくタスクが自分自身で準備したタスクで探索するってのは難しいところもあるかもしれないっていうかその評価というかスコアが出てこないと、そのスコアをもとに、モデルプロンプトを工夫したりとかそのモデルの重みにアクセスできるかまた、自由度が違ってくるんですが、先ほどその列シンクステップバイステップじゃなくて、その探索モデル自身に探索させることによって、新しいプロンプト文を選びましたみたいな感じであるんですけどそのような感じで、何でしょう、実現不可能な技術ではないその、何でしょう、もう一番これがうまくいくみたいなものを探すとすると探索空間が広すぎるんで、これが一番うまくいくPromptingだみたいなところ厳密に言えるのは難しいかもしれないんですが、今あるPromptingをさらに良くしていくというところは、実用化されてるかなと思います。

[0:46:01 - 0:46:41]
ありがとうございます。ちょっと時間ありますかね。あと1問ぐらい行きましょうかよ。マジョリティーボーディングで最終的にそうですねLLMにというかその回答、さっきの論文中だと、その回答時なので答えは18とか答えは21みたいな感じで数値として出てくる問題だったのでその数値の一致率というか、5個中何個中8と言ったかみたいな感じで多数決になるんですけど、そういうことは難しい。

[0:46:41 - 0:47:10]
場合ですと、LLMにその回答を評価させるどれが一番いいかっていうのを評価させるであったりとか別でモデルを組んであげて、その文章の良さを評価するモデルRLHF会で後半の会でリワードモデルっていう話があるんですけど文章に対してどれぐらい好ましいかっていうスコアを出すモデルを学習させることによってそのスコアをもとに選んでいくっていう手法があります。

[0:47:13 - 0:47:30]
はい、ありがとうございます。一旦質疑は終了でいいですかねまたお戻しするので、引き続きお願いします関係ないすけど、1000名受講者超えましたね1人減っちゃった。はいなんてまずはいい感じだと思います。はい。

[0:47:32 - 0:48:07]
はい。では後半の話ですね。今までがLM1個でLLMに指示出しであったりそのDecodingの工夫でよくする話だったんですが性能を良くするって話だったんですが、次はLLMだけじゃなくて、外部ツールであったり外部知識を利用することによって、性能を良くする手法メンテとLanguageModelについてお話しますここではこの概念というのはRAGとか、ツールユースであったりエージェントと呼ばれるものがこれに該当するかなと思います。

[0:48:09 - 0:49:13]
芸名フィットLanguageModel大きく分けるとRetrieverるargmentLanguageModelツールゲームといったLanguageモデルというものがありますそれぞれお話していきます。まずはなんで外部知識とかツールを使いたいのかっていうモチベーションなんですが、三つほど大きいいろいろあるんですが三つほど紹介しますと、一つが、タスクを解くのに必要な知識や能力は多様ですと、LLMだけでタスクを解かせようとした場合そのLLMにその能力を全部保持しておかないといけないっていうのがあるんですがそうすると結構大変ですと、学習も大変になりますと知識や外部のツールを活用することで効率よくそれを防げないかとそのツールを使うことで、タスクを成功できないかというのがありますと他小島さんがプレッシングステップバイステップで算数数学の問題とかつったんですけど間違った問題ってどこで間違えたのかって見てみますと、単純にその計算ミスですごい間違えてましたと。

[0:49:13 - 0:49:29]
計算ミスさえ合ってれば、計算さえ合ってればその過程みたいなのあってるので、成功しますよねみたいな感じでそのLMじゃなくても解けるような問題というかLLMが苦手なことは、それが得意なものにやらせようというところがあります。

[0:49:31 - 0:49:57]
もう一つが知識の更新ですと、知識に誤りが含まれているときにどう修正すればいいかと。そもそもLLMにどうやって知識が蓄えられてそれをどう修正するのかっていうのはすごい大きなリサーチクエスチョンで、今もずっと研究されてるんですが、アドホックに修正するのは結構大変ですとさらに新しいものを加えたいっていう場面もあるかと思います。

[0:49:57 - 0:50:16]
例えば大谷翔平選手が何本ホームランを打ったかっていうのは結構日々刻々と変わっていく事実とは思うんですがそれを学習データからまた違うその事情が変わった事実というものをうまく反映させるためにはどうすればいいかというのがあります。

[0:50:18 - 0:50:45]
そして信頼性というところで、Hallucinationという大きな問題があるんですけれども言語モデルは誤った知識であっても、最もらしく話してしまうとそれを、そういう問題があるので閉じちゃったサービスもありますとattentionisAllyouneedっていうのがこういう歌の歌詞にあったみたいなことを堂々と言ってるんですがそういう事実はないんですけど、最もらしく言っちゃうというのがあります。

[0:50:45 - 0:50:59]
LLMにだけ生成させるんじゃなくて、何かしらこの何を元に生成させているのかっていうのをうまくコントロールさせて生成させたい、信頼性を向上させたいというニーズもあるので、外部知識ツールを使いたいというものがあります。

[0:51:01 - 0:51:44]
そこでまずはRAGについて説明したいと思います。RetrieverるRetrieverるargmentRAG島でRetrieverるオブMetaGenerationというのがRAGなんですけれども、これがどういうものかといいますと検索と言語モデルを組み合わせたモデルになってますと例えばこういう入力文が与えられたときにそれに関連する文書というものを、知識データベース、これは普通にテキストデータとしてほ保持されてるものなんですけどそれを検索してあげるRetrieverというのが検索する機能を持つものなんですけど検索した上で、元の入力と検索された文章を入れることでLLMに出力をさせるというのが大まかな流れです。

[0:51:46 - 0:52:26]
ここで重要なRetrieverという役割が何をすしているのかというようなことをお話すると、Retrieverっていうのはどのように必要な文書を取ってくるかとそのための機能を提供します。Retrieverの役割というものは、外部で集めてるデータベースから、今与えられたQuery入力分に類似した文書を見つけることが役割ですとそれどう類似したものというか、類似度を測るかということで大きく分けて二つあります一つが、ATFIDFと呼ばれる手法に代表されるようなSparseな表現です。

[0:52:26 - 0:52:56]
これがその単語がこの文章に含まれてる含まれてない。というところで、その文章にこの単語が含まれてる01で、大きい行列というかそれを作ってあげて、ベクトルを作ってあげて、そんな表現をすることで、Retrieverろケースしますと、有名なPFIDFというのも有名なんですけど、よくRetrieverのベースラインとして使われるのが、DM25と呼ばれるものがあります。

[0:52:57 - 0:53:37]
もう一つがニューラルネットの表現空間で類似度を測るような、DenseRetrieverと呼ばれるものですと、こちらはその埋め込み空間で押さえる一度用いてRetrieverしてきますとこのベクトル空間に埋め込むためのモデルっていうのはな何でも良くて、BERTSentenceBERTと呼ばれるものであったりOpenAIが提供しているエンベディングAPIと呼ばれるものもこのように、ベクトル空間に押し込んでますと密な表現ニューラルネットによってせまらティック意味的な情報もうまく埋め込むことを期待してるので、ええ。

[0:53:38 - 0:54:18]
そういうせまらティックな検索には良いと呼ばれてます。Retrieverそのが満たすべき要件として二つ大きく分けてあります一つがある重要なキーワードを含んでいることというところでQuery部入力分に挙げられてるようなキーワードを出る文章を持ってこれるかどうかっていうのが、まずそれを持ってこれないと答えられるもの答えられないので重要なキーワードQueryに含まれるような重要なキーワードを含んでいるかどうかそれがSparseRetrieverというものが、得意としてるところです。

[0:54:18 - 0:55:38]
もう一つが文章の意味的な類似度を反映しているかというところで、同じキーワードを含んだ含めなかったとしても似たような概念で説明していたりとか、そういうところを反映したいので、何か質問に答えるような文章が含まれてるかどうかというのも大事なのでそこはDenseRetrieverが得意としていると言われるところですとニューラルレトリーバーDenseRetrieverニューラルネットワークの表現空間でに埋め込むための手法というものはいくつかあるんですが、一つがよく使われるというか、OpenAIのエンベディングAPIでベクトル化して検索しますみたいなのはこの真ん中の部類なんですが、Queryとドキュメントその蓄えてる知識データベースがあるとは思うんですがそれぞれをモデルにかけてあげて一つのベクトルに圧縮するというか埋め込んであげて、ここでの類似度を測ってあげて関連してる関連してないということをしますと、こちらこのドキュメントを1回埋め込んであげればQueryがくればそれを埋め込んであげて検索するだけなので早い計算コスト早いというのがあるんですがどうしてもその文章token列を一つのベクトルに押し込んじゃうので、表現力が低くなっちゃうという問題があります。

[0:55:39 - 0:56:17]
それに対してクロスEncoderというものがあってQueryとドキュメントどちらも同じネットワークに入れてあげて、入力、ここでTrasnformerで処理してあげて、最終的にスコアを出すみたいなものがあるんですが、こちら、マイドキュメント毎期マイドキュメントQueryが来るためにしないといけないので、表現力は高いんですけど、計算コストが高いっていうものがありますとそれらのいいとこ取りをしたのがコールBERTと呼ばれるような手法で、最終層の表現空間でうまく選んであげるというのがあります。

[0:56:18 - 0:56:59]
これら選択の余地いろいろあるので、迷ってしまうと思うんですが、あとはもう、計算コストとお金どれぐらいかけられるかのトレードオフかなと思います。DM25TASIDSでのようなSparseなものですと、別にGPUがなくてもCPUだけですごい安く早く検索できますというのが売りで、なんですが、あるベンチマークで検索結果みたいな評価すると、スコアは低いですとDPRとかコールBERTと呼ばれるような手法は、どうしても計算時間かかってしまうんですが、スコアっていうものは高くなります。

[0:57:00 - 0:57:18]
こちらCPUだけの計算結果なんですけどこれを、GPUを積んであげてCPUも積んであげると、確かに速度は速くなるんですがお金が高くなりますなのでどこまでお金をかけてどこまでパフォーマンスを上げたいかというところでどうRetrieverを使うかというのが一つ。

[0:57:19 - 0:58:04]
選択のデザインかなと思います。そしてRetrieverというものを1回だけしか使わないというわけでもなくRetriever複数組み合わせる手法もあります。それがDRAMと呼ばれるもので、大量のデータがあると思うんですけどそれを素早く、例えばBM25とか、PFIで負例のようなSparseRetrieverで素早くトップ100を持ってきますとその上でこのトップ100個に対してコールBERTであったりDPRエンベディングAPIとか使って、トップ10を選びますみたいな形でRetrieverを何回かいろんな種類使って、それぞれのいいとこ取りをしてやりましょうというのがディラックと呼ばれる賞ですそれでうまく検索結果を上げましょうというものがあります。

[0:58:05 - 0:58:21]
こちらもLLMにさせようということも、近年提唱されていて、LLMにPromptingしてあげることで、この文章どれが一番関連しやすいかを、このように順位付けして出してくれみたいなところもされたりします。

[0:58:23 - 0:59:15]
ここまでがRetrieverで検索する部分ですと、その検索した結果をどうつく使うかというのがジェネレーションですとこれもいろいろ流派があるんですが有名なものをいくつか紹介したいと思います。一つが、REPLUGと呼ばれる手法で検索した文章を元の入力にくっつけてコンテキストとして入力するものですこれがよくRAGと呼ばれるようなものです入力部に加えてあげて入力空間で条件付けしてあげるというのがRAGですとね、複数ある場合は複数校の予測アンサンブルすることもありますと入力文に入れるんじゃなくて、その途中のネットワークの表現空間で条件づけしたりといういろいろな流派があります。

[0:59:18 - 0:59:55]
そのように条件付けしてあげてコンテキストで条件付けしてあげると、何もしないRetrieverるっていうのがあの、ただ単にモデルにQueryを投げただけの場合と比べて検索結果を一緒に使った方が、このスコアが下がるほどいいんですけど、この赤のものを見てみると、DM25で持ってきた検索結果を一緒に整理をさせてあげると、どのモデルでもスコアが下がって性能上がってますと呼ばれ、言われてるので、RAGっていいですよねというところが言われてます。

[0:59:57 - 1:00:28]
ええ。ええ。モデルサイズ大きくなっても性能が改善されました。いうところです。そしてRetrieverLLMを学習、RAGの性能上げるときに、そのそれぞれで今のまま使うんじゃなくてそのRAGRetrieverとしてGenerationするそのパイプラインでうまくいくことが重要なので、それを考慮してFine-Tuningするというところもあります。

[1:00:28 - 1:00:56]
それでRetrieverFine-Tuningすることもありますし、LLMをFine-Tuningすることもありますと、性能を上げるためにはそういう工夫もあります。そしてそしてジェネレーションLanguageModelに生成させるというだけではなくて、RAGモデルが生成した結果をちょっとキャリブレーションしてあげるというか修正してあげるという使い方もありまして、こちらがKNプロンプトと呼ばれる手法になります。

[1:00:59 - 1:01:51]
それすると、性能も上がりますよねというところが言われています。RAGとRetrieverるオブメンテLanguageModelといっても様々な種類がありますとRetrieverルしてくるんですかどのようにテキスト着火しますかどのようにRetrieverをRetrieverしてきたものを使えますかというところ入力部に条件付けさせたり、中間層で条件つけさせたりとか、何回に1回Retrieverルしますかみたいな感じで、本当に様々ですとなのでそれぞれ良いところ悪いところ、コストとパフォーマンス、どうなるかというところもあるので、そのタスクに応じて選ぶべきかなと思います。

[1:01:54 - 1:03:04]
松尾研では論文を解説してくれるボットというものが常駐していて、リンクを投げると、要約してさらに質問論文に関する質問もSlack時計で聞けるというものがデプロイされていたりします。僕自身ちょっと質問回答にRAGが使えないかというところで発表したこともあり、ちょっと詳細は割愛するんですが質問文どう組むかっていうと質問文タイプ分けしますこれが実際に去年得られたような質問を、ちょっと擬似的にいじった分文章なんですけど、こういう質問文がありますとタイプ分けすると、こういう内訳ですと、これらの質問を答えるためにはどういう回答がしないといけないのかっていうところを考えてあげると、そのトピックどういうことに答えて欲しいかっていうそのトピックを特定してあげてそれを説明し、上げてそれに関連する文章を渡してあげるっていうのが大事かな。

[1:03:04 - 1:03:45]
それがどのタイプでも効くかなと思ってパイプライン組みました最初が質問文が与えられるので、それをどのテーマについて答えるべきかっていうのをワンショットPromptingによって検索クエリ化しますとさらに大規模言語モデルの文章って結構英語のものが多いので英語で検索クエリが出るように、海外の文章にヒットするようにしますとそれをGoogleの検索APで使って、記事引っ張ってきてそこから該当する文書を引っ張ってきますとそれを含めて答えさせるみたいなことを組んでみましたという形です。

[1:03:47 - 1:04:22]
そのようにRAGいろいろ応用がありますと本当にデザインの余地がありこれだけその応用で期待されてる部分もあるので、いろんな質問があると思うんですが業務特化のものを作りたい場合には、ちゃんとそのデータベースをきちんと作ることが大事かなとSAKeyをひたすら貯めたり、こういう質問が来そうだな含まれるドキュメントっていうのも検索されないか、焦りやすい形になるのか、メタデータつけられるのかとか、そういうのが大事かなと思います。

[1:04:23 - 1:04:42]
さらにベクトル検索するので、文書が多いと、そこがボトルネックで時間かかっちゃうっていうところもあり、ベクターDBと呼ばれるような形でベクトル検索を早くするための技術みたいなのもありますと、そちらも参照してください。

[1:04:43 - 1:05:02]
タスク上げるためタスク性能上げるためには、学習しなしじゃなくてRetrieverとかLMLanguageモデルを学習することもあります。最近の話題としては、LanguageModel入力、たくさん入るようになりましたと。

[1:05:02 - 1:05:25]
最近のGeminiGoogleが出してるチーム内というモデルでは、100万コンテキスト入りますと一味1Milliontoken入りましたこれがどれぐらいの長さというと、70万文字文字でいうと70万文字であったりとか、講座であった3文字とか11時間の音声データとか1時間の動画が入るようになりました。

[1:05:26 - 1:06:11]
こういうものが出てきてるので、ログコンテキストそのLLMのその入力部にとりあえず全部入力すればそれで終わりなのかロングコンテキストが出てきてRAGisDeadみたいな感じで、ちょっとネットで騒ぐこともあるんですが、よくよくちゃんと実験してみたりすると、モデルの進化も早いのでいろいろ課題も解決されてるとは思うんですが、報告されてる問題としては、例えばLostinTheMiddleと言われる有名な現象がありまして、その文章、その正解文書がそのプロ途中例えば20個関連文書本って入れますと、その中の一つだけが正解文書ですと、それを踏まえて答えられればいいんですけど、その文書がどこにあるか。

[1:06:12 - 1:07:18]
真ん中に置かれると、それを参照してないその文章がなかったときの性能に比べて落ちることもあるというか、もう何か混乱しちゃって変なこと言っちゃう。こともありますなので、入力部に入れれば性能が上がるかというとその入れ方も、どれぐらい入れるかというところも問題になりますとさらにさらに踏まえるべき事実というものが、どこ何か踏まえて答えないといけないのか、一文Int形式で、この住所は何、その住所がプロンプト中にバッチと書かれてるのであれば、簡単に答えられるっていうのはあるんですけど、甘えるべき事実が複数あると、それを全部踏まえて答えるようなタスクだと難しいですよねっていうのがありますとさらに関係ない文章があると落ちていきますというところも報告されているのであろうコンテキストで、とりあえずぶっ込めばいいんだっていうわけではなくて、細かいデザインの必要性があるかなと思います。

[1:07:18 - 1:07:38]
ただ、Google社とかOpenAI社をなるべくそういう問題が起きないようにFine-Tuningとかはモデル提供者側でおそらくやってると思うので、モデルのバージョンが上がるごとにそのまま問題っていうのはなくなってくるかもしれないんですが、RAGにおいては、いかに関係する文書を持ってくるかっていうところが大事かなと思います。

[1:07:40 - 1:08:59]
今回話しきれなかった話っていうのは、いろいろおすすめしてあげてるのでぜひ見てみてください。扇面とRAGMLの最後の部分でスツールユースとエージェントについてお話します。ツールユースのイメージなんですけれどもこちら天気のAPIお天気の東京の天気がどうか、今日の天気はどうかっていうところを聞くようなツールがあったときに決まった形式でロケーション東京として挙げてこのKeyとValueで投げてあげると、ウェザーが晴れですと返ってくるよねLLMを活用してこのインターフェイスに合うように政府政府にしてあげると、それ整形してあげることで、ツールを使えますとツールを使って、それでこういうふうに返ってきますこの出力結果をうまく使って次の推論に繋ぎ合わせるっていうのが大まかなイメージですと、そしてLLMにツールの使用までを判断させたり、またLLMに大きなタスク本って渡されて、それをサブタスク化してあげるそのサブタスクがそれぞれのAPIで解けるような形でしゃぶタスク化することによって、大きなタスクでもうまく解くようにするっていうのが正例ですとか、エージェントのイメージです。

[1:09:02 - 1:09:32]
で、既に皆さんに馴染みがあるかもしれない。例としてはコードの実行環境をツールとして組み込んで挙げた例として、Codeinterpreterというものがありますとただ、文章がサインプロットしてと言っても、綺麗な図を作成することはできないかもしれないんですが、この3波をプロットするような行動を書いてあげることで、その行動を実行した結果をユーザーに提示してあげて、綺麗なサインプロットがされてますということができるかなと思います。

[1:09:34 - 1:09:57]
このようにもう既に実世界でデプロイされてる講義面といったLanguageModelあるんですが、研究分野ではいろいろありまして、まず用語の整理として知識だけではなくて、外部ツールで拡張されたモデルはツールargmentIntLanguageモデルですと、その使われ方としては、生成を修正したり、補強したり、全エージェントを操作したりします。

[1:09:58 - 1:10:23]
外部ツールの例としてはよく使われるのは検索、コード実行環境、特定のAPIまたは別のモデルニューラルnetだったりします。少しそれぞれの研究を簡単に説明していきますと、チェーンソーと計算結果が計算ミスで間違えちゃうというところがありましたと。

[1:10:23 - 1:11:14]
その計算というのをもう全部Pythonでプログラミング実行環境を与えてあげて、そのPythonプログラム任せたらあとはそれを計算させるのは実行環境でやって、その結果を戻してやりましょうというのが、やったのがこのパールとプログラミングプログラムηLanguageModelと、10M走と思考の連鎖のときにそれぞれの計算式みたいなものを、プログラムコードで働かせるようにPromptingしてあげて推論するときに、そのコード実行させた結果を返すようにするということで、結果を得て性能上がりましたよと計算結果が間違ってるがために後ろの結果が間違っちゃうっていうのが主だったのでそこが改善されると性能上がりましたよねというところが確認されました。

[1:11:17 - 1:12:05]
プログラミングを実行環境として用意してあげると、RAGLanguageModelそのプログラムを書く能力も優れてるのでこのAPIを使うみたいな説明書があるとそれに則ってこういう行動したいときはこのAPIを使って使ってこうすればいけるはずだっていうのをプログラミングでプログラムコードで出力させてあげることで、何か人間がボールの中にブロック積み上げてみたいな感じで自然言語として与えたとしても、このAPIを繋ぎ合わせて一連とくようなコードを書いてあげて実行するというところでいろんなタスクをIntかせるようにしましたというところが報告されています。

[1:12:08 - 1:12:38]
さらにプログラミング実行環境だけじゃなくて、様々なツールがあったとしても、特定の文字列でツールの利用というものを教えてあげて、サーチ鍵括弧、何とかってケース入れるとそれを検索するようにしたりとかそういう言語自然言語文としてツールの使い方みたいなのをPromptingしてあげてそれが出てきたら、ツール実行して返す。

[1:12:38 - 1:13:13]
それを組み合わせることによって、ツールを利用させるっていうのがあります。このように自然言語文によってツールを使わせるというのもありますし、その紙使い方というのを、ただのPromptingだけじゃなくて、特定の文字列でそれが選ばれるように、そのタスクごとにFine-Tuningするっていうのもありますし、文字列じゃなくて、スペシャルtokenそのtokenとして、また詳しい話は多分来週からあるんですけど、言語モデルが扱うtokenっていう単位として、それを呼び出す。

[1:13:14 - 1:13:38]
Fine-Tuningしてあげることで、ツールの呼び出しをできるようになりますという研究があります。いろいろ本当にいろんなツールを組み合わせることで、いろんなCoTけるようになりますと鴨井遼っていうのが割と新しめの研究で、こんなこともできるんだとなるかなと思います。

[1:13:38 - 1:14:21]
さらにさらにLLMがツール自体を作っちゃうというものも、そういう研究もあります。そしてまた面白いのが、LLM自体をツールとして見立てて役割分担してタスクを解くという流れですと、これも同じ使ってるLLMは同じなんですけどPromptingによってLLMをツール化というかその特定の役割をするようにPromptingしてあげて役割分担することでタスクをやりますと入力文が与えられたときに何かしら答えをつくる、たたき台作りをするモデルがあってそれに対してそれで出てきた紙出力分に対してここを直す、ここを直すべきだっていうそのフィードバックをする。

[1:14:22 - 1:14:53]
Promptingによってフィードバックをするように機能させたLLMがありますと、そのフィードバックを活かして、回答を修正するLLMを作りますとこれをぐるぐる回すことで回答をよくしていきますと、同じ全部ベースのモデルは同じなんですけど、Promptingによって役割分担をしてあげることで、どん結構いろんなタスクでですね、この役割分担してタスクを解かせることで、出力性能が簡単に上がりますよと言われてます。

[1:14:55 - 1:15:10]
最近の研究ですと、AIサイエンティストと魚AIと日本の会社が最近話題この論文発表して話題になったんですが、この研究のワークフローっていうのを、LLMのエージェントによって自動化するということがあります。

[1:15:10 - 1:15:37]
研究のワークフローいろいろアイディア考えて、新規性あるか。このアイディアってどれぐらいいいかなみたいな。実験して、実験結果こうだから、もっと実験しようとかあって結果を得ますと、それ得て論文化しましょうっていう、そういう一連のプロセスがあるんですけどそれを全部LLMに、あとツールの利用もして、自動化しましたこういう論文ができましたみたいなところが報告されていたりします。

[1:15:40 - 1:16:14]
このように論文で報告されてることもありますし、手軽にツールを使ったものを自分で試してみたいということであれば、LLMをAPIとして提供してるサービス会社は、自分でそのツールを使うようなエージェントを作る機能をノーコードでするGPTisOpenAIthatGPTisaGoogleだと全部ですかねそういう名前で提供されてるので、それで実際に使ってみるというのもおすすめです。

[1:16:16 - 1:16:51]
Microsoft社もそういうのを出してたりします。もちろんプログラミングで自分でツールを作って、それこそ別のLLMを呼び出すみたいな複雑な処理をさせたいというところであれば、結構コード書かないといけない気がするんですがAPILMをAPIとして提供してるところは、Functionコールであったり、ツールユースという機能で、こういうふうにツールを定義してあげてやれば、ツールを使うような振る舞いをしますよという機能を提供してるのでそちらも見てみてください。

[1:16:54 - 1:17:18]
それぞれの話題でも、広いのでまずは講義メントIntLanguageModelというところで言語モデルをどう拡張するか言語モデルが何が得意で何が苦手なのか、そういう課題を知る。その上でどう設計すべきかっていうところでRAGサーベイ論文があるので、LMどう拡張できる売るのかな、いろんな事例を見ながらする場合にはこちらの論文を見てください。

[1:17:18 - 1:17:57]
そしてRetrieverる使って質問回答させたいということであれば、有名な良いチュートリアルもあるので、そちらもどうぞツールとエージェントに関しても、ぜひこれらの論文を参考にしてください。はい画面とLanguageモデルのまとめですと、ランゲ言語モデル協力なんですが計算ミスしたり、知識が更新するのは難しかったり、Hallucinationしたりという課題がありますと、それらを克服するための枠組みとして、メインテートLanguageModelというものがありました。

[1:17:57 - 1:18:25]
Retriever検索とRAGモデルを組み合わせたものがRetrieverをゲームエントランスモデルでどのようにRetrieverにするのか、Retrieverした情報をどう使うのかと、様々にデザインする余地がありますツールも外部ツールを使うことで計算効率計算高めることで、推論結果良くしたり、外部のモデル使うことでより高性能にタスクを解くことができました。

[1:18:27 - 1:18:50]
いうのが後半のまとめテストで、練習エヴェルトンさんがこれからする練習は実際にPromptingKeyを学んだFew-ShotプリンティングやチェーンソーとPromptingを実際に自分で実装しています講義MetaとRAGモデルの一種であるRetrieverRAGMetaGenerationのパイプラインを実際に組んでますというのが練習になります。

[1:18:51 - 1:19:16]
講座講義の部分は以上で残りは質疑応答で、その後演習に繋げたいと思います。はい川崎さんよろしくお願いしますありがとうございますちょっと質疑の時間にまた行きたいなと思うんですがなんか思ってたよりかなりね、大量の質問いただいてですねちょっと絞り込みできなかったんで逆に原田さんの方で今リンク貼ったんでこれ駄目かな。

[1:19:16 - 1:19:34]
ちょっと消しました。ちょっと内部で共有しますがつつそのリンク踏んでもらって、何か自分で自分でというか良さげなやつを、画面共有しつつ回答いただけるとありがたいありがたいかなと思いますありました。ちょっと今、はい、内部チャットの方で共有しております。

[1:19:34 - 1:20:00]
はい。どこですか。どこのLMのやつですね。Slackです。メンションしました。3見れるかな。アクセスできますか。見れそうでした。画面共有していただきます。ありがとうございます。残り10分ぐらいは質疑応答できそうで答えられるからすごいっす。

[1:20:05 - 1:20:26]
そっかな、うん。そうですね。はい。なるほどどうしよっか。上からするとでもどんどんなっちゃいますねProcessor内は新しい順に並んでるので後ろからやっていけばいいのか。そうですね。途中まで優先度をつけてたんですけど、ちょっと座の断念してしまいました。

[1:20:27 - 1:21:26]
途中からですね後半の話にちょっと文章ではなく、数値や画像のようなRAGの使い方、もちろんありますマルチモーダルにRAGするそのモデルもありますなので、画像をもとに答えさせたり動画の中から検索して答えさせたりみたいなことができるようになってますと現状どれぐらいできるのかみたいなのは、GoogleのGeminiの1.5のテクニカルレポートで結構面白い例が紹介されてて、例えばこの映画、映画の映画とかムービーをプロンプトに突っ込むんですけど、その映画でこういうことをしてるシーンはどこかみたいなところを答えさせたりとか小説まとめさせたりとか、音声を入力にして答えさせたりとかもありますいいえ。

[1:21:26 - 1:22:06]
マルチモーダルマルチモーダルでそういうRetrieverの開発もされたりします。RAGの将来性について何か考えてますか。RAGを使わずに、はい。これはちょっと紹介したんですがLostinTheMiddleとかもありますし来週詳しく説明はあるとは思うんですが、入力分が増えれば増えるほど計算コストって事情で聞いてきたりするので、そういう何かコ・ス・パを良くするためにもいかに質、必要な文章を小さく絞るのかっていうのは、運用上大事かなと性能上運用上大事かなと思いました。

[1:22:07 - 1:23:45]
ただなんですよ、既存ほど頑張らなくてもいい感じに答えられるようにはなってくるかなと思いますが、やっぱりいかに良い文章いいところを引っ張ってくるかってのは大事かなと思います。プロンプトでRAG様に追加でインプットした情報からだっけ外部情報だけ二値しく、これ難しいですよね今日も何かそういう論文が出てた気がするんですけど、そのモデルの内部の情報と、コンテキストに与えられたRetrieverルされた文章、どっちを優先して答えるかみたいなのは、結構難しいというか、そのメカニズム自体も解明するのは難しいんですがただやろうとすると、RAGも今はRetrieverるして生成するだけだったんですけど、もうRAGの評価でもよく使われるんですが、出てきた文章というか、まずそもそも非評価の話してないんで難しいんですちょっとはしょっちゃったんであれなんですけど、出てきた文章生成した文章が検索したものと一致してるかというかそれを含んで、答えてるかっていうのを、後段で処理するっていうかそれで何か変なこと言ってないかみたいなところを評価したりもするんですよねそれでそれをうまく工夫してあげることで、なるべくその外部情報を参照して答えさせることもできるかなと思います。

[1:23:46 - 1:24:01]
さらにジェネレーションLanguageモデルにさせるとそういうこともあるので、3章分、その経年のプロンプトみたいな感じで3章分でうまくモデル化、3章分だけでモデル化するということもあるかなと終わります。

[1:24:03 - 1:24:58]
これは、解決したのか、解決しない。一旦飛ばします。いいえ。どうやってデータセットを作るかですよね丸あるだとスケールしない。よく作られるベンチマークっていうのは、検索窓Googleの検索窓だったりそのあると思うんですけどあれにユーザーがタイプして、持ってきたものそれをクエスチョンとしてまず担保し、持ってきたの保持しておきますと、どのリンクが正しいか、っていうのも後から後付けでやってあげる。

[1:24:59 - 1:25:57]
というところで検索エンジンを使うことで、RAGのというか、Retrieverの性能を評価したりとかあるんですけど、タスクが何でしょう。難しくなったりとか路面がすごい固定されればされるほど、どうしても人間の手で作っちゃわないといけないので大変な部分はあるかと思いますこれを合成データセットというかLLMに何かそれも何かこれが関連してる関連してないとかこれで解決した解決してないみたいなシミュレーションさせて、擬似的にバーって作ってあげてそれを何ですかね、いろいろなやり方があるんですけど、そういうLMに判断させてLMTheAzureジャッジを使って、ゴールデンデータを作る方法もありますし、元の、何でしょう、こういう文章がありますとこの文章に関連する質問を作らせますと。

[1:25:57 - 1:26:14]
そうすることで、この文書を参照して答えさせられるような質問文みたいなのをLLMに作らせてあげて、そうすることで、この文章をもとに答える質問リストみたいなのを作ってあげてそれをページごとに作ってあげてかさ増しするみたいなこともあったりします。

[1:26:14 - 1:26:55]
なので、そうですね、そういうやり方とかますね。す。そうですよね。アーカイブIntアプリと紹介して、結構間違えること嘘言ったりすることもあるんですが研究する人が実際に論文読むのでざっと理解してんて言ってするだけに、理由はとどまってる気がするのでそれを完全に信じることはない気がするんですがやっぱり問題として問題意識としてはそれを広くいろんなユーザーに使ってもらおうとすると大変かもしれないですね。

[1:26:55 - 1:27:25]
なので、この回答根拠がどこから引っ張ってくるかみたいなのリンクとして、差し込んでそこをすぐ参照できるようにして、本当に合ってるかどうかを人手に委ねてあげるとか、そういう工夫もあったりすると思いますなのでシステムとして完璧にHallucinationすることってのは難しいのでいかにそれを何でしょう、カバーできる、その機構をシステムとして組み込むかみたいなのが一つ重要なものかなと思います。

[1:27:25 - 1:28:24]
あと何分であとさ、データの構造化はい大事ですね。どのような構造化を行えばよいでしょうか？これも結局RAGってRetrieverるしてくる部分とジェネレーションしてくる部分があるんですけど、いかに検索を、結局正しい文章を引っ張ってこないといけないのでそこがこけるとこけちゃうんですよね後ろの性能も良くならないのでなので、結局は検索エンジンをどう高性能に作るかみたいな問いに結構ぶつかるとは思いますと、Googleとか皆さん使ってGoogle検索とか他のヤフー検索とか使ってるかもしれないんですが、もうやっぱりGoogle検索下がれば下がるほどそれRAGちょっと自分で組んでみてなんかいい感じのこと引っ張ってこないなみたいなことあるかもしれないんですが、Google検索とかするとやっぱすごいなとなるかなと思いますと。

[1:28:24 - 1:30:45]
それがどういう構造で、Google検索の仕組みとかもオープンになってない部分があるのであれなんですが、有名なのがそのページ同士のページランクっていうのが、97年ぐらいに伝承されてそれでGoogle検索エンジン作りましたみたいな感じなんですけどそのページ、どの文章が重要かっていうのがページのリンク情報というかそのどのページがどのページからリンクされてるか、が大事だっていうところそれを組み込むことで、そのページの品質みたいなのをランク付けしてあげるというとこで文章だけの情報を使ってランキングするんじゃなくてそういうMetaデータというか文章以外に付与できる例えば、何ですかね、一番重要な文書群というかそのどの組織にも、このマニュアルは絶対とりあえず最初読めみたいな文章があるとは思うんですけどそういう文書文を必ず検索するようにするんだ、ですとか、そういうデータベースごとに管理を変えてあげるとか、こういう質問はここのデータベースみたいな感じこのデータベースにはこういう情報がありますみたいなのをデータベースごとに区切ってやるとか、Metaデータとして日付新しいものを良いとしてやるかとか更新された日付が新しければ新しいほど情報が新しいとして、社内DBとして作るかという感じでいかに他の情報をうまく使えるかっていうのも大事かなと思うし、SSMって何百でしょす村口モデルじゃないかスモールRAG社性能との差だと思うので、どうコ・ス・パを考えるかって感じなんですがとりあえず最初RAGにしろ何にしろ何かパイプラインを組むときは一番いいモデルというかコストは一旦考えずにどこまでいけるのかなっていうのを考える上で、一番いい性能の良いモデルでモデルあとはそれを良くしていく方向っていうのは結構いろいろあると思うので、今どれぐらいいけるのかなっていうのを確かめる上でも、大きいものも出る高性能なお金かかるかもしれないんですけど生のものを使うってのは大事かなと思いますというところで、時間が来たので以上にします。

[1:30:45 - 1:32:32]
それではベルトんさんお願いします。はい。よろしくお願いしますここから練習の方は宇津ベルトの方が担当させていただきます。はい事務局共有したんですけど今回の演習の方ではGoogleコラボを使うのでまずそのGoogle Cloudという環境について軽く説明させていただきます具体的なドキュメントの方は、ですね結果、手引きの手引きの演習環境のGoogle Cloudの使用方法というところにあるので詳しく見たい方はこちら読み込んでいただいて簡単に説明させていただくとGoogleコラボの方だとページを起動していただいて、画面の名称とか調整に関してちょっと割愛させていただくんですけど演習した結果の保存ファイルとか保存したい場合は、ファイルメニューからドライブにコピーなどして、コピーを保存などして保存してくださいここ一番大事なところになるんですが演習ファイルの起動の方法に関してですがまず、皆さんドライブの方開いていただいて、Googleドライブのを開いていただいてそこに.枚PYNPファイルがあるので最初のファイルがあるのでこちらクリックしていただければ開ける人はそのままGoogleコラボで開いてもらって、このような画面が出る場合には、Googleからを選択することでコラボの方で演習を実施することは出来事ができます。

[1:32:33 - 1:32:53]
はい一部講義とかだとGoogleのドライブの方にせえマウントする人とかがあるんですがその辺もここら辺読んでいただいていればどのような形でマウントできるかってのがわかると思います。はい。大体環境に関しては、ちょっと簡単にですが、このような形でお願いします。

[1:32:54 - 1:33:09]
ちょっと練習の方に移りたいと思います。練習の方ですねちょっと先ほど軽く本当ちょっとですけどか修正したので、事前にダウンロードしちゃってる方とかは、ちょっと再ダウンロードとかしていただけるとありがたいです。

[1:33:10 - 1:33:31]
はい講義の間ではちょっと演習の方はデモンストレーションという形で講師の方が行うのでちょっと皆さん手が輪がちょっと手をと一緒に動かしていくっていうな形にはならないのでちょっと皆さんは、生講義終了後とかにアーカイブの動画を見ながらちょっとそれ一緒に追いながら動かしていただけるとありがたいです。

[1:33:32 - 1:33:57]
はいそれでは書内容入っていきます。ですね今回の講義ではちょっとPromptingであったり揚げメンテとLanguageモデルに関しては使ったんですが各回の演習はそれぞれ講義で扱った内容を実際に実装していくっていう流れになっていきます今回は特にPromptingに関してオープンに扱えるモデルっていうのをHuggingFaceと呼ばれるプラットフォームから読み込んでそこから実装等していきます。

[1:34:00 - 1:34:13]
具体的な内容に関しては、本講義で扱ったPromptingのいろんな手法であったりだとか、argmentLanguageモデルの一種であるRAGRetrieverRAG面テッドGenerationに関して実装していきます。

[1:34:16 - 1:34:57]
はいですね今回ちょっとGPTの方を使うのでランタイムの方からランタイムC4のGCPで動かせるようにしているのでC4の方で動かしていただけるとありがたいです。はいそれではまずはモデルをオープンに公開されてるモデルをですね実際に読み込むためにHuggingFaceの方からログインしていただき、HuggingFaceの方へログインしていただきたいんですがここを動かしていただければこのような形で出るので、そのHuggingFaceで発行されているアクセスのtoken等をここに貼り付けてもらえれば、これをサクセスするってなればログインできます。

[1:34:59 - 1:35:38]
はいこれ量子化に必要なパッケージって書いてあるんですけどちょっと後で話します。ですね実際にここでモデルを読み込んでいきますと僕の方、時間がかかるので事前に読み込んでいるんですがここで遠くないTheMLそのモデルをモデルが扱う値に変換するようなモデルですLLMが使える値に変換するモデルを読み込むと、ていきます今回1000ちょっと質問をくれたんですが、Meta社が出しているLlama3の8Billonの方を用いて動かしていきたいと思い、実装していきたいと思っています。

[1:35:43 - 1:36:07]
はいこちらですね8Billonでちょっとかなり大きいモデルになるので読み込むのに時間がかかったりとかGPUの方メモリかなり使うので、メモリが足りないままだったりとか不安の場合には考慮量子化の方ここず、実行し、有効にしてここの方も有効にしていただければ、小さく載るモデル載せることができるので、よろしくお願いします。

[1:36:12 - 1:37:26]
はいそれではですね、実際にLLMの方のモデルを使っていきたいと思うんですが例えばプロンプトですねこちらがモデルに私入力になるんですけど今回このMaxPlayerBERTOneは打ち上げ時モデルフリー負例ってことで簡潔にRAG言語モデルについて説明してっていうタスクを例えば与えるとしますそのように与えられたモデルっていうのを遠くない座でモデルLLMが理解しやすい形に変換するといったことをして、それをですねこの実際に正例とするところの入力として与えてあげますし、ここでHuggingFaceのTrasnformerの方だと基本的に同じような仕組みになるんですけど実際に出力させる性成分の長さであったりだとか、Decodingの手法っていうのをここで設定することができますこのサンプルのフォースにするとですね、襟ぐり離散アグリーDecodingになるので必ず皆さん多分全く同じような結果が出てくるようになると思いますあとはGLUEにしてTemperatureの方とか、ここは有効にしていただくとちょっと変わった答えが出てくると思います。

[1:37:30 - 1:38:05]
HuggingFaceのTrasnformerLibraryがよく使われている理由としては、基本的にどのようなモデルに家であっても扱う方法モデルが2と同じような方法で全部動かすことができてわかりやすいからっていうような理由があると生成結果とか見てみると、このXプレーンな場内ラウンジLanguageモデルフリー3という出力に対して、次に最もらしい言葉としてこのような形で出力がどんどん生成されていく様子が見えると思います。

[1:38:06 - 1:38:40]
はい。ですねそれではここから実際にPromptingのテクニックに関して見ていきたいと思います。これ以上関係ないですまずはですねZero-Shotという形で、モデルにQAのタスクをたかせていくんですが、Zero-Shotという形でこのようなタスクとかせてみると、ちょっと時間かかりますね。

[1:38:52 - 1:39:39]
出ましたねこんな形で本来こういう一つの値を選んで回答させてしてもらいたいというなタスクにはなるんで洲鎌正成の結果がこのような形で、こちらユーザー側質問者側としては全く望んでないような巻きフォーマットで結果が出てくるとこのようなものを実際どうやって解決していくかってことにはなるんですけど今ですね出力が何回試しても変な形になるっていうのをわかりやすくするためにちょっと5回ぐらい生成するようにしちゃってるんですがこれ2回目の方も今、剣道って形で大括弧がついちゃってる状態でした望ましくない形で出てますね。

[1:39:40 - 1:39:57]
次にFew-Shotの方、Few-Shotと呼ばれるもし言われるこのデモンストレーションをプロンプトに追加することでQAを解かせたかせるっていうのは手法をやってみたいと思います。これもちょっとQuery会場多いので2回ぐらいにするんですか。

[1:39:58 - 1:40:42]
このような形で生成させることでこちらの予想と期待としては、大学校もついてない答えだけの単語が出てくるように、このし、エーフィショットLayerなるかなっていうのがこちらの規定ではあるんですが果たして出ましたこういう形でちゃんと買い応えもあってて、ちゃんと大括弧先ほどの例だと大括弧ついちゃってたのが、つい出ないような、ちゃんとした形で出力が出ると、こういう方法でうんこういう方法で出力の性能っていうのを上げることができます。

[1:40:43 - 1:42:10]
はい2回目もちゃんとこのような形だったので、たまたまってわけでもなくconfigショットが、確かに3効果があるってのがわかったと思います。はい。そしたら次にチェーン部相当に関して見ていきたいと思います今回ちょっと違うソートが、Promptingが提唱された論文中の例使うんですがまず何もない状態何もチーム相当をしない状態で、回答を生成させてみると早いですね20ドルとなんかよくわかんない回答が根拠もなく回答が出てくるとそれに対してそれではしチンarg相当と呼ばれる方法をとって、によって、こういう形で洗礼を入れてか、思考の過程っていうのを生成させるような形で促してみると、時間がかかりますが、こんなこのような形でちゃんと施工の過程があって且つ、回答もちゃんと正しく合ってると、こういう形で遅延を相当の方は性能の向上が見られると思います。

[1:42:11 - 1:42:44]
次に最後Zero-Shotチャーム層と呼ばれるレッツ正規化ステップステップというふうに入れることで性能が上がるっていう方法が講義中でもあったと思うんですがこちらに関してもやってみると、はいこちらもちょっと出力が長いですけど正しく思考の過程が出て、最後ちゃんとオリビア外8ドルレフトって形で残ってますっていう形で回答が出ています。

[1:42:45 - 1:43:23]
はい。では最後に些細なPromptingPLaMoとの差によって出力がどのように変わってくるかっていうものを見ていきたいと思います。上の文章だと改行ないです。空白ないんですが、二つ目の文章では空白ありにしています加えてここでサンプルフォースって形にすることでグリーンDecodingにしているので、何かあっても同じような結果た皆さんが、の環境であっても多分同じような結果が出てくるようになるので、この二つの出力の差っていうのが明確にわかると思います。

[1:43:37 - 1:44:10]
ちょっと先に下ですけど、このような形でPromptingいろんな方法があるんですが他にも、方法といろんなことがあるのでここら辺の資料を見ていただければより深く知れると思います。結果出ましたが、この1個の単純な全角のスペースを入れるだけでこのような形での出力が内容はほぼ同じなんですが文章の長さって点でわかる通り出力が変わってくるってのがわかると思います。

[1:44:12 - 1:44:28]
はい。ちょっと早くなりましたがここまでがPromptingに関する内容になります。次RetrieverのargmentGenerationということで、argmentGeneration系の話に移っていきたいと思います。

[1:44:33 - 1:45:13]
ちょっとごめんなさいここですねここからはなんですけど先ほどまで使ってたのがLlama3な8Billonってことで事前学習までのLlama3モデルになるのもなるんですがここから事後学習15名MetaMetaLlama38BillonInstructってモデルを使っていきます理由としては、単純にその日本語において、もう割と性能がいいからですねまずこのモデル使って、東京大学の松尾研究室が開校する大講義言語モデルではどのような内容は使えますかというような質問に関して回答させてみましょう。

[1:45:15 - 1:46:43]
ではですねつまりその言語LLMモデル側が、これに関してどのような知識を持ってるのかっていうのを確かめる目的でやっています。はい、出ましたこんな形で結果が出るんですが、ちょっと割と読むとですねそれっぽいことは言ってるんですが実際はそう正しくはなくてですね、このようなこと漢字で正しくない情報っていうのが正しい情報をどのように形で言わせるかってことで講義中でもありましたがIntelRetrieverRAGエンジン現地モデルで言われたような話ですけど、正しい情報をLMに渡してあげると今回でいくと講義の内容に関して、これ講義ページにあった内容ですけどこいつを入れてあげますプロンプトとしてはこんな形になります先ほどの質問の上に、講義の実際の内容を入れた情報を加えてあげてるっていう形ですねこれを訂正し、これをプロンプトにして生成させてみると、はい。

[1:46:43 - 1:47:04]
このような形で先ほどのこの与えた情報に基づいて正しいLM今回の講座に関する情報に関して説明してくれます。はいここでコンテキストRAG系の話に関してわかったところで実際のRAGの実装の方に移っていきたいと思います。

[1:47:05 - 1:47:31]
はいまずはですねリトリーブのValueの実装という形ことで、モデルがどのようにその関連する情報っていうものを、質問に関連する情報っていうものを取得するかっていうような実装に移っていきます。ここではですねエンベディングモデルを使うのでこちらもちょっと僕の方で事前にダウンロードしておいたんですが皆さんの方でダウンロードするときは、これもちょっと時間がかかってしまうかもしれないです。

[1:47:32 - 1:47:56]
はい。では具体的な方法に関しては、質問文をベクトルに埋め込んでベクトルに変換して、そのベクトルと次の内容ですけど、関連する文章それぞれベクトルにした関連する文章の類似度っていうものをここでコサイン類似度等で取ってくる。

[1:47:56 - 1:48:24]
ことになります。実際にちょっと埋め込んでみましょう。ベクトル化してみましょうそうするとこのモデルは、ではですね、1024次元に埋め埋め込んで、このような形でベクトル化されるんですが、実際正しく文書をどのように取得するかということに関して、ちょっとこちらを見ていただいて、今三つの情報を与えています。

[1:48:24 - 1:48:47]
一つが言語モデルに関する講座の内容、もう一つは深層生成モデルに関する講座の内容で最後に強化学習に関する講座の内容になりますここから正しく文章を取ってきてほしいのでこの質問に関連する文書を取ってきてほしいのでこの一番上の本講座サマースクールの一環として、大規模言語モデルから始まる文章をうまく取ってくれたら成功になります。

[1:48:48 - 1:49:10]
ちょっと動かしたんですが、実際に埋め込んで計算させてみると、この文章のスコアは73、この文章のスコア63。この文章のスコア73.16ちょっと誤差ではあるんですけど最もスコアの高いインデックスがこれってことになって正しく文章が取ってくれているのがわかると思います。

[1:49:10 - 1:49:30]
このような形でRetrieverルの方ってのは、RAGの方で実装されていきます。次にですねドキュメントの用意になるんですがちょっと補足にはなるんですがRAGシステムっていうのは実装する上でかなり重要な工程かなと思うのが実際にドキュメントを作るってところになります。

[1:49:30 - 1:50:07]
ドキュメントは何かっていうと、先ほどの例でいうようなこの本講座はっていうのは、この一つ一つの文章の対応ドキュメントって言います。どうしてこの部分が重要かというと先ほどコンテキストレングスが伸びてたくさんの文章入れられるようになったよって話もあったんですが基本的にAPIの文字数制限等でたくさんの文章を入れられないとか、あとは実際検索の生のときに未処理の膨大な文章をそのまま使うってなると、関係ない文章とかが入ってくるので検索性能が下がったりとかしますね。

[1:50:07 - 1:50:49]
あとは内容的なノイズになったりとかすることもあるので、これらWikipediaとか見て想像してもらえばわかるんですけど長文の文章っていうのをどのように分割して一つ一つの単位としてチャンクとして見るかってっていうのがRAGの課題の一つになってくるかなと思いますその方法の方法、やり方としては主によく言われてるのが三つあって例えば文字数例えば1000文字単位で区切るであったりとか段落やショーなどで区切るとか意味的なまとまりを考慮して例えばLLMに指で分割してみたいな感じでやらせたりとかすることもありますけど、そういう形でドキュメントをとってきたりします。

[1:50:50 - 1:51:12]
今回の実装では、二つ目の段落やショーなどに基づいて分割していくやり方でやっています。今回使うドキュメントとして松尾研究室がこのラボニュースっていうページから情報を取ってきてここに関する内容に関して、モデルでちゃんと正しく回答させることができるかってことを見ていきたいと思います。

[1:51:14 - 1:51:35]
ですね実際に文章を取ってきてみるとこのような形で、今のやり方ではURLとその公開日と内容とTaxonomyページのタイトルが、このような形で取ってこられる形になりますねこんなのでこの中から正しい文章をうまく取ってきて回答させるっていうのがRAG全体的なフローになります。

[1:51:36 - 1:52:38]
実際にやってみましょうということで今回東京大学松尾岩澤研究室GENIACプロジェクトにおいて開発したモデルは何かっていうのは質問を解かせてみたいと思います。前屈テキストは先ほど作ったこれらの文章になるのでこのミッションの中から、この狸88Billonっていうような言葉が入っている文章を取ってくれるかっていうようなことになります実際やってみると、やってみて上位3件取ってみるとですね一つ目はちょっと違うんですが二つ目にちゃんと正しく狸8掛け8Billonって文字が入った文章を取ってくることができていますなので実際のフローだと、これで取ってきた文章をそのままこのような形で前直前に挿入することで、質問に対して、はいこんな形でタヌキ88Billonを開発し公開しましたというような正しい最新の情報を含んだ生成をさせるっていうな流れになります。

[1:52:42 - 1:53:29]
はいこういった補足でちょっと申し訳ないすけどこれはC4では回らないので、リソースがある方もしリソースがある方がいればLforだったりとかで回していただければいいんですが李ランクって言われる講義内で森ランクって呼ばれる方法があったと思うんですがあまりランクではですね最初にRAGにおいて使われるリランキングって方で最初に大雑把にかんコストが安いようなモデルとかでたくさん関連する文書をなるべくちょっと多くとってくると、その次に計算コスト高い色精度がηEモデル等を使って、取ってきたいくつかの文章の中から、より洗練され、洗練して文章を取ってくれってなことを行います。

[1:53:29 - 1:53:59]
ここでもちょっと実際にやってみてるがあるんですけど、先ほどまで使ってた割と軽いモデルを使って今上位5件とってきています。これにこの後ここで使って呼び出してるちょっと重いモデル、コストが高いモデルを実際に使って2回目の文章をやってこのような形でですね関連するより、より関連する文書って取ってくるっていう流れが2ランクでは行われています。

[1:54:02 - 1:54:21]
はいこれ補足になりますこれ動かしたい方向けに、ですね先日話もあったと思うんですがタヌキGENIACプロジェクトで開発された狸88Billonというのを実際に動かすことができるような部分を作ってみたこれはC4で動かせるので実際やってみたい方動かしてみてください。

[1:54:23 - 1:54:48]
はい演習の方流れ以上になります。ありがとうございました。川崎さんお願いしますありがとうございます。ちょっと同じくですね質問いくつかいただいているので、ちょっと書いていただければなと思います。ちょっと内部のSlackで共有しますね改めてはい、わかりました。

[1:54:48 - 1:55:05]
ちょっと画面共有しつつして回答いただければなと思います上から回答しなかった演習で回答しなかったやつが上から三つかなと思いますですか。うん、そうですね。ただ一番上の部でプレーないらしいかもしれないんで飛ばしてわかりました。

[1:55:05 - 1:55:50]
はい。10サンプルフォースを使うとLlamaでQていくときに同じモデルが回答が得られるという理解で合ってますか。モデル更新とLlamaの調整等が行われて出力結果が再現されない。モデル更新が行われるかわからないですけど行われたらその読み込む時点で内部パラメータってが変わってくると思うので出力は変わって、変わっちゃうんじゃないかなと思うんですけど基本的にモデルの方で内部のパラメータとは変わらないので変わらないと思うので、まずサンプルフォース使ってればGreedyDecodingになって継続的に同じ回答を得られるかなっていうふうに思います。

[1:55:53 - 1:56:12]
はい。コラボの有料版を使った場合に想定されるコストですか。無料版で基本的に動かせるようにしているので、有料版使った場合のコスト等を考えなくても大丈夫かなと思います何かフィルタリング外れちゃってますね。ごめんなさいそうですか。

[1:56:12 - 1:56:39]
リンクから踏んでもらえればと思います。ちょっと受講者の皆さんにお伝えしておくと無償版って言ってんのがC4というインスタンスですね。基本的に演習のはあの無償版で使えますもうちょっと何ランクのところでしたっけをやりたいって方はちょっとDay4じゃ厳しいかもしれないので有償版がLforだったりそれ以上のGPTは使えるんですけどそこをお使いくださいっていうような案内になるのかなと思ってます。

[1:56:39 - 1:57:23]
なんで基本的に無償版でいけるっていうふうに、あの後なんだ、ご理解いただければと思います。ごめんなさいこれですね演習のノートブックでログイン作成するとなりますがその次のステップでモデルのダウンロードが失敗しますってことに関してなんですけどこちらですね、何か事前に案内があった気がするんですが、今回Llama3使うっていうことでMeta社にちょっとモデルを使いたいですっていうな申請の報告拡充する必要がありましてこちらの方がちょっと進んでいないとHuggingFaceの方でのログインを作成するんですがMetaの方からちょっとモデル使う権利を与えられないよって形でCANnotACCESSゲーテDay4言われるになります。

[1:57:24 - 1:57:44]
なのでですねここ演習の方にここにURL書いてあるのでここから申請を行っていただければ、ちゃんと動かせると思います。RAGをまた外れちゃってますね何か別な文体で使った方がいいかもしれないですはい。こっちか。

[1:57:46 - 1:58:09]
かな。ちょっと俺が開きすぎてました。うん、はい、はい。グラフRAGのアプローチは、これ値演習とは違うかな。ちょっと演習に関してそしたら大丈夫ですかね、質問ははい大丈夫です回収に関しての質問は大丈夫だと思いますHBM講義はいありがとうございました。

[1:58:11 - 1:58:44]
演習は以上になりますかね。瓜田さん。はい。ちょっとください。多分大丈夫です。動いてるんで、ちょっと僕ちょっとここら辺詳しくないんであれなんですけど、動いてるんで大丈夫かなと思います。はい、はい、わかりました、ありがとうございますちょっとまた春の質問くるかもしれないんでという定義をお送りいただければと思いますテキストで回答できればと思います。

[1:58:45 - 1:59:07]
はいベイズさんありがとうございました。ありがとうございました。はい、ありがとうございます最後ですね僕からちょっといくつかお話させてください画面共有します宿題の説明ですこの手引きの方にもあるんですけども今回から宿題が開始されます。

[1:59:10 - 1:59:30]
やり方結論から言うと全部ここに書いてるんで見てもらえればということなんですが、一応簡単に進めさせていただくと、今回に関してはちょっと演習でGLUEクラブを使う、使われたと思うのでちょっとここは割愛しますねなので宿題もGoogleクラブを使います。

[1:59:30 - 2:00:14]
はい。なんで同じようにファイルを開いてくださいっていうことになりますね。宿題のこうじゃないか。宿題の場所も同じようにリンク貼ってるので、こっからたどっていってください。Omnicampusじゃないよ、教材フォルダの中にあれあれだよ、それフォルダ1はいにあるので宿題からですね04番宿題っていうところにありますDay2の宿題AIさんのノートブックのファイルがあるので、これをコラボで開いてください。

[2:00:14 - 2:00:43]
これ以上編集ファイルにも、に関しても同じですね。GoogleがLaboratoryで開くと、開いていただくとこんなようなあのファイルが開けると思いますですねこれらを解いていただいて最後まで実行していただくとCSVファイルが生成されますそれをOmnicampusにて作って提出してくださいっていうことなんですけどこれってまだ開かれてないんですかね登坂さんここの所間違えてますはい、大丈夫です。

[2:00:43 - 2:00:58]
ありがとうございます。はい。なんでCSVファイルをですねOmnicampusに入って自分のコースのところで、の宿題ここに出てくるはずなんで、こっからにアップロードしていただくっていうようなご案内なります。

[2:00:59 - 2:01:15]
ちょっとごめんなさい次関数.すれば大丈夫だとIRちゃいます。ちょっと時間過ぎちゃってますがもしお使いお付き合いくださいはいなんでこの今日の分ですねDay2出てきますので、このような形でここクリックしてCSVをアップロードする。

[2:01:15 - 2:01:35]
いうような感じでしていただくと、祭典が確か1日に1回でしたっけに走るあの橋締め切り後2回か。そっか締め切りまであれですね、何国会でもファイルは更新できるか、採点は1回のみになるってことですね。なのではい。

[2:01:35 - 2:02:41]
これで提出いただければというふうに思います。詳細もあの手引きに書いてありますので、もし不明な方こちらをご覧いただければというふうに思いますのでよろしくお願いいたします。はい。あとですねちょっと一部の方からご質問いただいたんですけども、ちょっと何か講座で習ったことをアウトプットしたりとか社内に展開したりっていうようなお話をいただいてましてちょっと松尾研のこのLM、LMコミュニティのですねWikipedia植木といいますか能書のページがあるんですけど、こちらでちょっと皆さんの共有で何かナレッジを食べていければいいなというふうに思ってちょっとスペースを作ったので、ぜひこちらの中でどんどん何か学びだったり気づいたところ、メモみたいなところを書いていただければというふうに思います皆さんと共有しつつ、何か1個の大きなあのデータベースにできればなというふうに思ってますのでちょっとそちらも皆さんやっていきましょうというところで、詳細はSlackの方でまたSlackの講座のジェネラルで、後ほど流しますのでそちらご活用いただければというふうに思っておりますので、よろしくお願いします。

[2:02:41 - 2:02:57]
はい。ということですいませんちょっと時間過ぎちゃいまして、本日の講座、以上とさせていただきます登坂さん、最後締めをよろしくお願いします。はい、ありがとうございました。皆様ご事項お疲れ様でした。Omnicampusでログインして出欠アンケートに回答してください。

[2:02:58 - 2:03:18]
提出締切は本日から一種単語の水曜日17時です。出欠アンケートの提出をもって出席といたします。また本日の宿題を公開いたしました宿題のファイルの格納先や出席宿題の提出方法は、受講の手引きをご覧ください。受講の手引きのへのリンクは、受講のお知らせメールに記載されています。

[2:03:19 - 2:03:23]
それでは講義を終了いたします。本日はご受講いただきありがとうございました。