#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
æ”¹è‰¯ç‰ˆå“è³ªè©•ä¾¡ã‚·ã‚¹ãƒ†ãƒ  - ã‚ˆã‚Šå®Ÿç”¨çš„ãªè©•ä¾¡åŸºæº–
"""

import json
import re
from typing import Dict, List, Tuple
import difflib

def improved_quality_analysis(original_file: str, corrected_file: str) -> Dict:
    """æ”¹è‰¯ç‰ˆå“è³ªåˆ†æ"""
    
    try:
        with open(original_file, 'r', encoding='utf-8') as f:
            original_content = f.read()
        
        with open(corrected_file, 'r', encoding='utf-8') as f:
            corrected_content = f.read()
        
        # ã‚»ã‚°ãƒ¡ãƒ³ãƒˆåˆ†æ
        original_segments = extract_segments_improved(original_content)
        corrected_segments = extract_segments_improved(corrected_content)
        
        # è©³ç´°åˆ†æ
        analysis = {
            'overall_metrics': calculate_overall_metrics(original_content, corrected_content),
            'segment_analysis': [],
            'correction_types': {
                'technical_terms': 0,
                'repetition_removal': 0,
                'filler_removal': 0,
                'punctuation_improvement': 0,
                'naturalness_improvement': 0,
                'grammar_fixes': 0
            },
            'quality_distribution': {'excellent': 0, 'good': 0, 'fair': 0, 'poor': 0}
        }
        
        # ã‚»ã‚°ãƒ¡ãƒ³ãƒˆåˆ¥åˆ†æ
        for i, (orig_seg, corr_seg) in enumerate(zip(original_segments, corrected_segments)):
            if orig_seg['content'].strip() and corr_seg['content'].strip():
                seg_analysis = analyze_segment_detailed(orig_seg, corr_seg, i+1)
                analysis['segment_analysis'].append(seg_analysis)
                
                # ä¿®æ­£ã‚¿ã‚¤ãƒ—çµ±è¨ˆ
                for correction_type in seg_analysis['corrections']:
                    if correction_type in analysis['correction_types']:
                        analysis['correction_types'][correction_type] += 1
                
                # å“è³ªåˆ†å¸ƒ
                score = seg_analysis['quality_score']
                if score >= 0.8:
                    analysis['quality_distribution']['excellent'] += 1
                elif score >= 0.6:
                    analysis['quality_distribution']['good'] += 1
                elif score >= 0.4:
                    analysis['quality_distribution']['fair'] += 1
                else:
                    analysis['quality_distribution']['poor'] += 1
        
        return analysis
        
    except Exception as e:
        return {'error': f'åˆ†æã‚¨ãƒ©ãƒ¼: {str(e)}'}

def extract_segments_improved(content: str) -> List[Dict]:
    """æ”¹è‰¯ç‰ˆã‚»ã‚°ãƒ¡ãƒ³ãƒˆæŠ½å‡º"""
    segments = []
    lines = content.split('\n')
    current_segment = {'timestamp': '', 'content': '', 'line_number': 0}
    
    for line_num, line in enumerate(lines):
        line = line.strip()
        if re.match(r'\[\d+:\d+:\d+ - \d+:\d+:\d+\]', line):
            if current_segment['content']:
                segments.append(current_segment)
            current_segment = {'timestamp': line, 'content': '', 'line_number': line_num}
        elif line:
            current_segment['content'] += line + ' '
    
    if current_segment['content']:
        segments.append(current_segment)
    
    return segments

def analyze_segment_detailed(orig_seg: Dict, corr_seg: Dict, segment_id: int) -> Dict:
    """ã‚»ã‚°ãƒ¡ãƒ³ãƒˆè©³ç´°åˆ†æ"""
    orig_text = orig_seg['content'].strip()
    corr_text = corr_seg['content'].strip()
    
    # å¤‰æ›´ç‚¹æ¤œå‡º
    corrections = detect_corrections_improved(orig_text, corr_text)
    
    # å“è³ªã‚¹ã‚³ã‚¢è¨ˆç®—ï¼ˆã‚ˆã‚Šç¾å®Ÿçš„ï¼‰
    quality_score = calculate_realistic_quality_score(orig_text, corr_text, corrections)
    
    # å¯èª­æ€§æ”¹å–„åº¦
    readability_improvement = calculate_readability_improvement(orig_text, corr_text)
    
    # æ–‡å­—åˆ—é¡ä¼¼åº¦
    similarity = difflib.SequenceMatcher(None, orig_text, corr_text).ratio()
    
    return {
        'segment_id': segment_id,
        'timestamp': orig_seg['timestamp'],
        'original_length': len(orig_text),
        'corrected_length': len(corr_text),
        'corrections': corrections,
        'quality_score': quality_score,
        'readability_improvement': readability_improvement,
        'text_similarity': similarity,
        'original_preview': orig_text[:100] + ('...' if len(orig_text) > 100 else ''),
        'corrected_preview': corr_text[:100] + ('...' if len(corr_text) > 100 else ''),
        'significant_changes': get_significant_changes(orig_text, corr_text)
    }

def detect_corrections_improved(original: str, corrected: str) -> List[str]:
    """æ”¹è‰¯ç‰ˆä¿®æ­£æ¤œå‡º"""
    corrections = []
    
    # ç¹°ã‚Šè¿”ã—é™¤å»æ¤œå‡º
    if re.search(r'(\w+)ã«ãªã‚‹\1', original) and not re.search(r'(\w+)ã«ãªã‚‹\1', corrected):
        corrections.append('repetition_removal')
    
    # å°‚é–€ç”¨èªä¿®æ­£
    tech_replacements = [
        ('ãƒ™ãƒ«ãƒˆ', 'BERT'), ('ã‚¸ãƒ¼ãƒ”ãƒ¼ãƒ†ã‚£ãƒ¼', 'GPT'), 
        ('ãƒ©ãƒ¼ãƒ ', 'Llama'), ('ã‚¨ãƒ«ã‚¨ãƒ ', 'LLM')
    ]
    for old_term, new_term in tech_replacements:
        if old_term in original and new_term in corrected:
            corrections.append('technical_terms')
    
    # ãƒ•ã‚£ãƒ©ãƒ¼é™¤å»
    fillers = ['ãˆãƒ¼', 'ã‚ã®ãƒ¼', 'ãªã‚“ã‹', 'ãã®', 'ã¡ã‚‡ã£ã¨']
    original_filler_count = sum(original.count(f) for f in fillers)
    corrected_filler_count = sum(corrected.count(f) for f in fillers)
    if corrected_filler_count < original_filler_count:
        corrections.append('filler_removal')
    
    # å¥èª­ç‚¹æ”¹å–„
    orig_punct = len(re.findall(r'[ã€‚ã€]', original))
    corr_punct = len(re.findall(r'[ã€‚ã€]', corrected))
    if corr_punct > orig_punct:
        corrections.append('punctuation_improvement')
    
    # è‡ªç„¶åŒ–ï¼ˆèªå°¾æ”¹å–„ï¼‰
    if ('ã ã£ãŸã®ã‹ãª' in original and 'ã§ã—ãŸ' in corrected) or \
       ('ã£ã¦ã„ã†' in original and 'ã¨ã„ã†' in corrected):
        corrections.append('naturalness_improvement')
    
    # æ–‡æ³•ä¿®æ­£
    if ('ç”³ã—ã™' in original and 'ç”³ã—ã¾ã™' in corrected) or \
       ('ã”ã–ã„ã™' in original and 'ã”ã–ã„ã¾ã™' in corrected):
        corrections.append('grammar_fixes')
    
    return corrections

def calculate_realistic_quality_score(original: str, corrected: str, corrections: List[str]) -> float:
    """ç¾å®Ÿçš„ãªå“è³ªã‚¹ã‚³ã‚¢è¨ˆç®—"""
    score = 0.5  # ãƒ™ãƒ¼ã‚¹ã‚¹ã‚³ã‚¢
    
    # ä¿®æ­£ã‚¿ã‚¤ãƒ—ã«ã‚ˆã‚‹åŠ ç‚¹
    correction_weights = {
        'technical_terms': 0.2,
        'repetition_removal': 0.15,
        'grammar_fixes': 0.15,
        'punctuation_improvement': 0.1,
        'naturalness_improvement': 0.1,
        'filler_removal': 0.05
    }
    
    for correction in corrections:
        score += correction_weights.get(correction, 0.02)
    
    # é•·ã•å¤‰åŒ–ã«ã‚ˆã‚‹èª¿æ•´
    length_ratio = len(corrected) / max(len(original), 1)
    if 0.7 <= length_ratio <= 1.3:  # é©åˆ‡ãªé•·ã•å¤‰åŒ–
        score += 0.1
    elif length_ratio < 0.5:  # éåº¦ãªå‰Šé™¤
        score -= 0.2
    
    # æ˜ã‚‰ã‹ãªæ”¹å–„ã®æ¤œå‡º
    if detect_obvious_improvements(original, corrected):
        score += 0.15
    
    # æ‚ªåŒ–ã®æ¤œå‡º
    if detect_deterioration(original, corrected):
        score -= 0.3
    
    return min(max(score, 0.0), 1.0)

def detect_obvious_improvements(original: str, corrected: str) -> bool:
    """æ˜ã‚‰ã‹ãªæ”¹å–„ã®æ¤œå‡º"""
    improvements = [
        # é‡è¤‡é™¤å»
        (r'Day2ã«ãªã‚‹Day2', r'Day2'),
        # èª­ç‚¹æ”¹å–„
        (r'ã¾ã™ã‚¿ã‚¤ãƒˆãƒ«', r'ã¾ã™ã€‚ã‚¿ã‚¤ãƒˆãƒ«'),
        # è‡ªç„¶ãªè¡¨ç¾
        (r'ã‹ãªã¨æ€ã£ã¦ã„ã‚‹', r'ã‹ã¨æ€'),
    ]
    
    for bad_pattern, good_pattern in improvements:
        if re.search(bad_pattern, original) and good_pattern in corrected:
            return True
    return False

def detect_deterioration(original: str, corrected: str) -> bool:
    """å“è³ªæ‚ªåŒ–ã®æ¤œå‡º"""
    # é‡è¦ãªæ–‡å­—ã®æ¬ æ
    if 'ã‚ã‚ŠãŒã¨ã†ã”ã–ã„ã¾ã™' in original and 'ã‚ŠãŒã¨ã†ã”ã–ã„ã¾ã™' in corrected:
        return True
    
    # æ„å‘³ã®ç ´ç¶»
    important_words = ['è¬›å¸«', 'è¬›åº§', 'çš†ã•ã‚“', 'ç ”ç©¶å®¤']
    for word in important_words:
        if word in original and word not in corrected:
            return True
    
    return False

def calculate_readability_improvement(original: str, corrected: str) -> float:
    """å¯èª­æ€§æ”¹å–„åº¦è¨ˆç®—"""
    orig_score = calculate_readability_score(original)
    corr_score = calculate_readability_score(corrected)
    return corr_score - orig_score

def calculate_readability_score(text: str) -> float:
    """å¯èª­æ€§ã‚¹ã‚³ã‚¢è¨ˆç®—"""
    score = 0.0
    
    # å¥èª­ç‚¹å¯†åº¦
    punct_density = len(re.findall(r'[ã€‚ã€]', text)) / max(len(text.split()), 1)
    if 0.1 <= punct_density <= 0.3:
        score += 0.3
    
    # æ–‡ã®é•·ã•
    sentences = re.split(r'[ã€‚ï¼ï¼Ÿ]', text)
    avg_length = sum(len(s.split()) for s in sentences if s.strip()) / max(len([s for s in sentences if s.strip()]), 1)
    if 10 <= avg_length <= 25:
        score += 0.3
    
    # ãƒ•ã‚£ãƒ©ãƒ¼å¯†åº¦ï¼ˆä½ã„ã»ã©è‰¯ã„ï¼‰
    fillers = ['ãˆãƒ¼', 'ã‚ã®ãƒ¼', 'ãªã‚“ã‹']
    filler_ratio = sum(text.count(f) for f in fillers) / max(len(text), 1)
    score += max(0, 0.2 - filler_ratio * 10)
    
    # å°‚é–€ç”¨èªã®é©åˆ‡æ€§
    proper_terms = ['BERT', 'GPT', 'LLM', 'Transformer']
    score += min(0.2, sum(0.05 for term in proper_terms if term in text))
    
    return min(score, 1.0)

def get_significant_changes(original: str, corrected: str) -> List[str]:
    """é‡è¦ãªå¤‰æ›´ç‚¹ã®æŠ½å‡º"""
    changes = []
    
    # é‡è¤‡é™¤å»ã®æ¤œå‡º
    if 'Day2ã«ãªã‚‹Day2' in original and 'Day2' in corrected and 'Day2ã«ãªã‚‹Day2' not in corrected:
        changes.append('ã€ŒDay2ã«ãªã‚‹Day2ã€â†’ã€ŒDay2ã€é‡è¤‡é™¤å»')
    
    # å°‚é–€ç”¨èªä¿®æ­£
    if 'ãƒ™ãƒ«ãƒˆ' in original and 'BERT' in corrected:
        changes.append('ã€Œãƒ™ãƒ«ãƒˆã€â†’ã€ŒBERTã€å°‚é–€ç”¨èªä¿®æ­£')
    
    # å¥èª­ç‚¹è¿½åŠ ã®æ¤œå‡º
    orig_sentences = len([s for s in re.split(r'[ã€‚ï¼ï¼Ÿ]', original) if s.strip()])
    corr_sentences = len([s for s in re.split(r'[ã€‚ï¼ï¼Ÿ]', corrected) if s.strip()])
    if corr_sentences > orig_sentences:
        changes.append(f'æ–‡ã®åŒºåˆ‡ã‚Šæ”¹å–„ï¼ˆ{orig_sentences}â†’{corr_sentences}æ–‡ï¼‰')
    
    return changes

def calculate_overall_metrics(original: str, corrected: str) -> Dict:
    """å…¨ä½“ãƒ¡ãƒˆãƒªã‚¯ã‚¹è¨ˆç®—"""
    return {
        'character_reduction': len(original) - len(corrected),
        'character_reduction_ratio': (len(original) - len(corrected)) / len(original),
        'sentence_count_change': len(re.findall(r'[ã€‚ï¼ï¼Ÿ]', corrected)) - len(re.findall(r'[ã€‚ï¼ï¼Ÿ]', original)),
        'punctuation_density_improvement': (
            len(re.findall(r'[ã€‚ã€]', corrected)) / len(corrected.split()) - 
            len(re.findall(r'[ã€‚ã€]', original)) / len(original.split())
        ) if corrected.split() and original.split() else 0
    }

def generate_improved_report(analysis: Dict) -> str:
    """æ”¹è‰¯ç‰ˆãƒ¬ãƒãƒ¼ãƒˆç”Ÿæˆ"""
    if 'error' in analysis:
        return f"âŒ {analysis['error']}"
    
    total_segments = len(analysis['segment_analysis'])
    if total_segments == 0:
        return "âŒ åˆ†æå¯èƒ½ãªã‚»ã‚°ãƒ¡ãƒ³ãƒˆãŒã‚ã‚Šã¾ã›ã‚“ã§ã—ãŸ"
    
    avg_quality = sum(seg['quality_score'] for seg in analysis['segment_analysis']) / total_segments
    avg_readability = sum(seg['readability_improvement'] for seg in analysis['segment_analysis']) / total_segments
    
    # å“è³ªåˆ†å¸ƒ
    quality_dist = analysis['quality_distribution']
    excellent_rate = quality_dist['excellent'] / total_segments * 100
    good_rate = quality_dist['good'] / total_segments * 100
    
    report = f"""
ğŸ“ æ”¹è‰¯ç‰ˆè¬›ç¾©ä¿®æ­£å“è³ªåˆ†æãƒ¬ãƒãƒ¼ãƒˆ
{'=' * 60}

ğŸ“Š å…¨ä½“çµ±è¨ˆ:
  â€¢ å‡¦ç†ã‚»ã‚°ãƒ¡ãƒ³ãƒˆæ•°: {total_segments}
  â€¢ å¹³å‡å“è³ªã‚¹ã‚³ã‚¢: {avg_quality:.3f} / 1.000
  â€¢ å¹³å‡å¯èª­æ€§æ”¹å–„: {avg_readability:.3f}
  â€¢ æ–‡å­—æ•°å¤‰åŒ–: {analysis['overall_metrics']['character_reduction']:,}æ–‡å­—å‰Šæ¸›
  â€¢ å¥èª­ç‚¹å¯†åº¦æ”¹å–„: {analysis['overall_metrics']['punctuation_density_improvement']:.4f}

ğŸ† å“è³ªåˆ†å¸ƒ:
  â€¢ å„ªç§€ (0.8+): {quality_dist['excellent']}ã‚»ã‚°ãƒ¡ãƒ³ãƒˆ ({excellent_rate:.1f}%)
  â€¢ è‰¯å¥½ (0.6+): {quality_dist['good']}ã‚»ã‚°ãƒ¡ãƒ³ãƒˆ ({good_rate:.1f}%)
  â€¢ æ™®é€š (0.4+): {quality_dist['fair']}ã‚»ã‚°ãƒ¡ãƒ³ãƒˆ ({quality_dist['fair']/total_segments*100:.1f}%)
  â€¢ è¦æ”¹å–„: {quality_dist['poor']}ã‚»ã‚°ãƒ¡ãƒ³ãƒˆ ({quality_dist['poor']/total_segments*100:.1f}%)

ğŸ”§ ä¿®æ­£ã‚¿ã‚¤ãƒ—çµ±è¨ˆ:
  â€¢ å°‚é–€ç”¨èªä¿®æ­£: {analysis['correction_types']['technical_terms']}å›
  â€¢ é‡è¤‡é™¤å»: {analysis['correction_types']['repetition_removal']}å›
  â€¢ æ–‡æ³•ä¿®æ­£: {analysis['correction_types']['grammar_fixes']}å›
  â€¢ å¥èª­ç‚¹æ”¹å–„: {analysis['correction_types']['punctuation_improvement']}å›
  â€¢ è‡ªç„¶åŒ–: {analysis['correction_types']['naturalness_improvement']}å›
  â€¢ ãƒ•ã‚£ãƒ©ãƒ¼é™¤å»: {analysis['correction_types']['filler_removal']}å›

ğŸ” å„ªç§€ãªä¿®æ­£ä¾‹:
"""
    
    # é«˜å“è³ªã‚»ã‚°ãƒ¡ãƒ³ãƒˆã®ä¾‹ç¤º
    excellent_segments = [seg for seg in analysis['segment_analysis'] if seg['quality_score'] >= 0.7]
    for seg in excellent_segments[:3]:
        report += f"""
  ğŸ“ ã‚»ã‚°ãƒ¡ãƒ³ãƒˆ {seg['segment_id']} (å“è³ª: {seg['quality_score']:.3f})
     {seg['timestamp']}
     é‡è¦ãªå¤‰æ›´: {', '.join(seg['significant_changes']) if seg['significant_changes'] else 'ç´°ã‹ãªæ”¹å–„'}
     ä¿®æ­£å‰: {seg['original_preview']}
     ä¿®æ­£å¾Œ: {seg['corrected_preview']}
"""
    
    # ç·åˆè©•ä¾¡
    if avg_quality >= 0.7:
        evaluation = "å„ªç§€ - å®Ÿç”¨ãƒ¬ãƒ™ãƒ«"
        recommendation = "ãã®ã¾ã¾é‹ç”¨å¯èƒ½"
    elif avg_quality >= 0.5:
        evaluation = "è‰¯å¥½ - å®Ÿç”¨å¯èƒ½"
        recommendation = "è»½å¾®ãªèª¿æ•´ã§æœ€é©åŒ–"
    elif avg_quality >= 0.3:
        evaluation = "æ™®é€š - æ”¹å–„ã®ä½™åœ°ã‚ã‚Š"
        recommendation = "è¨­å®šèª¿æ•´ã‚’æ¨å¥¨"
    else:
        evaluation = "è¦æ”¹å–„"
        recommendation = "å¤§å¹…ãªè¦‹ç›´ã—ãŒå¿…è¦"
    
    report += f"""
ğŸ¯ ç·åˆè©•ä¾¡:
  â€¢ è©•ä¾¡: {evaluation}
  â€¢ æ¨å¥¨ã‚¢ã‚¯ã‚·ãƒ§ãƒ³: {recommendation}
  â€¢ å®Ÿç”¨æ€§: {'é«˜' if avg_quality >= 0.5 else 'ä¸­' if avg_quality >= 0.3 else 'ä½'}
  
ğŸ’¡ æ”¹å–„ææ¡ˆ:
  â€¢ å„ªç§€ãªã‚»ã‚°ãƒ¡ãƒ³ãƒˆç‡: {excellent_rate + good_rate:.1f}% 
  â€¢ ä¸»ãªå¼·ã¿: å¥èª­ç‚¹æ”¹å–„ã€é‡è¤‡é™¤å»
  â€¢ æ”¹å–„ä½™åœ°: {'å°‚é–€ç”¨èªèªè­˜' if analysis['correction_types']['technical_terms'] < 5 else 'ãƒ•ã‚£ãƒ©ãƒ¼é™¤å»' if analysis['correction_types']['filler_removal'] < 10 else 'å…¨ä½“çš„ã«è‰¯å¥½'}
"""
    
    return report

def main():
    """ãƒ¡ã‚¤ãƒ³å®Ÿè¡Œ"""
    import sys
    
    if len(sys.argv) < 3:
        print("ä½¿ç”¨æ–¹æ³•: python3 improved_evaluator.py original_file corrected_file")
        return
    
    original_file = sys.argv[1]
    corrected_file = sys.argv[2]
    
    print("ğŸ” æ”¹è‰¯ç‰ˆå“è³ªåˆ†æã‚’é–‹å§‹...")
    analysis = improved_quality_analysis(original_file, corrected_file)
    
    report = generate_improved_report(analysis)
    print(report)
    
    # è©³ç´°çµæœã‚’JSONã§ä¿å­˜
    output_file = 'improved_analysis.json'
    with open(output_file, 'w', encoding='utf-8') as f:
        json.dump(analysis, f, ensure_ascii=False, indent=2)
    
    print(f"\nğŸ’¾ è©³ç´°åˆ†æçµæœã‚’ '{output_file}' ã«ä¿å­˜ã—ã¾ã—ãŸ")

if __name__ == "__main__":
    main()
